{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infant resting state fMRI preprocessing\n",
    "This notebook contains preprocessing tailored to infant resting state fMRI collected in 5-8 month olds. \n",
    "\n",
    "The processing steps for the fMRI broadly include:\n",
    "* Slice-time correction\n",
    "* Rigid realignment\n",
    "* Co-registration to the sMRI (T2-weighted structural MRI)\n",
    "* Artifact detection:\n",
    "    - Motion\n",
    "    - Global intensity outliers\n",
    "* De-noising to remove:\n",
    "    - Component noise associated with white matter and CSF\n",
    "    - component noise associated with motion\n",
    "    - Censoring/scrubbing of individual volumes detected as artifacts in the previous step\n",
    "    - Frame-wise displacement\n",
    "* Bandpass filtering\n",
    "* Spatial smoothing\n",
    "* Registration to infant sample template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "from os import listdir, makedirs\n",
    "from os.path import isdir\n",
    "from nipype.interfaces.io import DataSink, SelectFiles # Data i/o\n",
    "from nipype.interfaces.utility import IdentityInterface, Function     # utility\n",
    "from nipype.pipeline.engine import Node, Workflow, MapNode        # pypeline engine\n",
    "from nipype.interfaces.nipy.preprocess import Trim\n",
    "\n",
    "from nipype.algorithms.rapidart import ArtifactDetect\n",
    "from nipype.interfaces.fsl.preprocess import SliceTimer, MCFLIRT, FLIRT, FAST, SUSAN\n",
    "from nipype.interfaces.fsl.utils import Reorient2Std, MotionOutliers\n",
    "from nipype.interfaces.fsl.model import GLM\n",
    "from nipype.interfaces.fsl.maths import ApplyMask, TemporalFilter\n",
    "from nipype.interfaces.freesurfer import Resample, Binarize, MRIConvert\n",
    "from nipype.algorithms.confounds import CompCor\n",
    "from nipype.interfaces.afni.preprocess import Bandpass\n",
    "from nipype.interfaces.afni.utils import AFNItoNIFTI\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "from nipype.interfaces.ants import Registration, ApplyTransforms\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "#set output file type for FSL to NIFTI\n",
    "from nipype.interfaces.fsl.preprocess import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "# MATLAB setup - Specify path to current SPM and the MATLAB's default mode\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('~/spm12')\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "\n",
    "# Set study variables\n",
    "studyhome = '/Users/catcamacho/Box/SNAP/BABIES'\n",
    "#studyhome = '/Volumes/iang/active/BABIES/BABIES_rest'\n",
    "raw_data = studyhome + '/raw'\n",
    "output_dir = studyhome + '/proc/rest_preproc'\n",
    "workflow_dir = studyhome + '/workflows'\n",
    "#subjects_list = open(studyhome + '/misc/subjects.txt').read().splitlines()\n",
    "subjects_list = ['021']\n",
    "\n",
    "template_brain = studyhome + '/templates/T2w_BABIES_template_2mm.nii.gz'\n",
    "template_wm = studyhome + '/templates/BABIES_wm_mask_2mm.nii.gz'\n",
    "template_mask = studyhome + '/templates/T2w_BABIES_template_2mm_mask.nii.gz'\n",
    "\n",
    "proc_cores = 2 # number of cores of processing for the workflows\n",
    "\n",
    "vols_to_trim = 4\n",
    "interleave = False\n",
    "TR = 2.5 # in seconds\n",
    "slice_dir = 3 # 1=x, 2=y, 3=z\n",
    "resampled_voxel_size = (2,2,2)\n",
    "fwhm = 4 #fwhm for smoothing with SUSAN\n",
    "\n",
    "#changed to match Pendl et al 2017 (HBM)\n",
    "highpass_freq = 0.08 #in Hz\n",
    "lowpass_freq = 0.1 #in Hz\n",
    "\n",
    "mask_erosion = 1\n",
    "mask_dilation = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## File handling Nodes\n",
    "\n",
    "# Identity node- select subjects\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                     name=\"infosource\")\n",
    "infosource.iterables = ('subject_id', subjects_list)\n",
    "\n",
    "\n",
    "# Data grabber- select fMRI and sMRI\n",
    "templates = {'struct': raw_data + '/{subject_id}-BABIES/skullstripped_anat.nii.gz',\n",
    "            'func': raw_data + '/{subject_id}-BABIES/rest_raw.nii.gz'}\n",
    "selectfiles = Node(SelectFiles(templates), name='selectfiles')\n",
    "\n",
    "# Datasink- where our select outputs will go\n",
    "substitutions = [('_subject_id_', '')]\n",
    "datasink = Node(DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = output_dir\n",
    "datasink.inputs.container = output_dir\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nodes for preprocessing\n",
    "\n",
    "# Reorient to standard space using FSL\n",
    "reorientfunc = Node(Reorient2Std(), name='reorientfunc')\n",
    "reorientstruct = Node(Reorient2Std(), name='reorientstruct')\n",
    "\n",
    "# convert files to nifti\n",
    "reslice_struct = Node(MRIConvert(out_type='niigz',\n",
    "                                 conform_size=2,\n",
    "                                 crop_size=(128, 128, 128),\n",
    "                                ),\n",
    "                   name='reslice_struct')\n",
    "# Segment structural scan\n",
    "segment = Node(FAST(no_bias=True, \n",
    "                    segments=True, \n",
    "                    number_classes=3), \n",
    "               name='segment')\n",
    "\n",
    "# Trim first 4 volumes using nipype \n",
    "trimvols = Node(Trim(begin_index=vols_to_trim), name='trimvols')\n",
    "\n",
    "#Slice timing correction based on interleaved acquisition using FSL\n",
    "slicetime_correct = Node(SliceTimer(interleaved=interleave, \n",
    "                                    slice_direction=slice_dir,\n",
    "                                   time_repetition=TR),\n",
    "                            name='slicetime_correct')\n",
    "\n",
    "# Motion correction- MEL\n",
    "motion_correct = Node(MCFLIRT(save_plots=True, \n",
    "                              mean_vol=True), \n",
    "                      name='motion_correct')\n",
    "\n",
    "# Get frame-wise displacement for each run: in_file; out_file, out_metric_plot, out_metric_values\n",
    "get_FD = Node(MotionOutliers(metric = 'fd',\n",
    "                             out_metric_values = 'FD.txt',\n",
    "                             out_metric_plot = 'motionplot.png',\n",
    "                             no_motion_correction=False),\n",
    "                 name='get_FD',)\n",
    "\n",
    "# register BOLD to anat\n",
    "coregT2 = Node(Registration(args='--float',\n",
    "                            collapse_output_transforms=True,\n",
    "                            initial_moving_transform_com=True,\n",
    "                            num_threads=1,\n",
    "                            output_inverse_warped_image=True,\n",
    "                            output_warped_image=True,\n",
    "                            sigma_units=['vox']*3,\n",
    "                            transforms=['Rigid', 'Affine', 'SyN'],\n",
    "                            terminal_output='file',\n",
    "                            winsorize_lower_quantile=0.005,\n",
    "                            winsorize_upper_quantile=0.995,\n",
    "                            convergence_threshold=[1e-06],\n",
    "                            convergence_window_size=[10],\n",
    "                            metric=['Mattes', 'Mattes', 'CC'],\n",
    "                            metric_weight=[1.0]*3,\n",
    "                            number_of_iterations=[[100, 75, 50],\n",
    "                                                  [100, 75, 50],\n",
    "                                                  [70, 50, 20]],\n",
    "                            radius_or_number_of_bins=[32, 32, 4],\n",
    "                            sampling_percentage=[0.25, 0.25, 1],\n",
    "                            sampling_strategy=['Regular',\n",
    "                                               'Regular',\n",
    "                                               'None'],\n",
    "                            shrink_factors=[[4, 2, 1]]*3,\n",
    "                            smoothing_sigmas=[[2, 1, 0]]*3,\n",
    "                            transform_parameters=[(0.1,),\n",
    "                                                  (0.1,),\n",
    "                                                  (0.1, 3.0, 0.0)],\n",
    "                            use_histogram_matching=False,\n",
    "                            write_composite_transform=True,\n",
    "                            dimension=3),\n",
    "               name='coregT2')\n",
    "\n",
    "# apply transform to func\n",
    "applyT2xform = Node(ApplyTransforms(reference_image=template_brain, \n",
    "                                    dimension=4), \n",
    "                    name = 'applyT2xform')\n",
    "\n",
    "# register anat to template\n",
    "reg_temp = Node(Registration(args='--float',\n",
    "                             collapse_output_transforms=True,\n",
    "                             initial_moving_transform_com=True,\n",
    "                             num_threads=1,\n",
    "                             output_inverse_warped_image=True,\n",
    "                             output_warped_image=True,\n",
    "                             sigma_units=['vox']*3,\n",
    "                             transforms=['Rigid', 'Affine', 'SyN'],\n",
    "                             terminal_output='file',\n",
    "                             winsorize_lower_quantile=0.005,\n",
    "                             winsorize_upper_quantile=0.995,\n",
    "                             convergence_threshold=[1e-06],\n",
    "                             convergence_window_size=[10],\n",
    "                             metric=['Mattes', 'Mattes', 'CC'],\n",
    "                             metric_weight=[1.0]*3,\n",
    "                             number_of_iterations=[[100, 75, 50],\n",
    "                                                   [100, 75, 50],\n",
    "                                                   [70, 50, 20]],\n",
    "                             radius_or_number_of_bins=[32, 32, 4],\n",
    "                             sampling_percentage=[0.25, 0.25, 1],\n",
    "                             sampling_strategy=['Regular',\n",
    "                                                'Regular',\n",
    "                                                'None'],\n",
    "                             shrink_factors=[[4, 2, 1]]*3,\n",
    "                             smoothing_sigmas=[[2, 1, 0]]*3,\n",
    "                             transform_parameters=[(0.1,),\n",
    "                                                   (0.1,),\n",
    "                                                   (0.1, 3.0, 0.0)],\n",
    "                             use_histogram_matching=False,\n",
    "                             write_composite_transform=True, \n",
    "                             fixed_image=template_brain),\n",
    "                name='reg_temp')\n",
    "\n",
    "# apply transform to func\n",
    "applyxform = Node(ApplyTransforms(reference_image=template_brain, \n",
    "                                  dimension=4), \n",
    "                  name = 'applyxform')\n",
    "\n",
    "# unzip the nifti for ART\n",
    "gunzip = Node(Gunzip(), name='gunzip')\n",
    "\n",
    "# Artifact detection for scrubbing/motion assessment\n",
    "art = Node(ArtifactDetect(mask_type='file',\n",
    "                          parameter_source='FSL',\n",
    "                          norm_threshold=0.25, #mutually exclusive with rotation and translation thresh\n",
    "                          zintensity_threshold=2,\n",
    "                          use_differences=[True, False], \n",
    "                          mask_file=template_mask),\n",
    "           name='art')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data QC nodes\n",
    "def create_coreg_plot(epi,anat):\n",
    "    import os\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    \n",
    "    coreg_filename='coregistration.png'\n",
    "    display = plotting.plot_anat(epi, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'coregistration to anatomy')\n",
    "    display.add_edges(anat)\n",
    "    display.savefig(coreg_filename) \n",
    "    display.close()\n",
    "    coreg_file = os.path.abspath(coreg_filename)\n",
    "    \n",
    "    return(coreg_file)\n",
    "\n",
    "def check_mask_coverage(epi,brainmask):\n",
    "    import os\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    \n",
    "    maskcheck_filename='maskcheck.png'\n",
    "    display = plotting.plot_anat(epi, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'brainmask coverage')\n",
    "    display.add_contours(brainmask,levels=[.5], colors='r')\n",
    "    display.savefig(maskcheck_filename)\n",
    "    display.close()\n",
    "    maskcheck_file = os.path.abspath(maskcheck_filename)\n",
    "\n",
    "    return(maskcheck_file)\n",
    "\n",
    "make_coreg_img = Node(name='make_coreg_img',\n",
    "                      interface=Function(input_names=['epi','anat'],\n",
    "                                         output_names=['coreg_file'],\n",
    "                                         function=create_coreg_plot))\n",
    "\n",
    "make_checkmask_img = Node(name='make_checkmask_img',\n",
    "                      interface=Function(input_names=['epi','brainmask'],\n",
    "                                         output_names=['maskcheck_file'],\n",
    "                                         function=check_mask_coverage))\n",
    "make_checkmask_img.inputs.brainmask = template_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180618-08:26:23,631 workflow INFO:\n",
      "\t Generated workflow graph: /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/graph.png (graph2use=flat, simple_form=True).\n",
      "180618-08:26:23,872 workflow INFO:\n",
      "\t Workflow preprocwf settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "180618-08:26:23,903 workflow INFO:\n",
      "\t Running in parallel.\n",
      "180618-08:26:23,909 workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n",
      "180618-08:26:23,998 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocwf.selectfiles\" in \"/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/selectfiles\".\n",
      "180618-08:26:24,19 workflow INFO:\n",
      "\t [Node] Running \"selectfiles\" (\"nipype.interfaces.io.SelectFiles\")\n",
      "180618-08:26:24,37 workflow INFO:\n",
      "\t [Node] Finished \"preprocwf.selectfiles\".\n",
      "180618-08:26:25,909 workflow INFO:\n",
      "\t [Job 0] Completed (preprocwf.selectfiles).\n",
      "180618-08:26:25,912 workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 2 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n",
      "180618-08:26:25,977 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocwf.reorientfunc\" in \"/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/reorientfunc\".\n",
      "180618-08:26:25,977 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocwf.reorientstruct\" in \"/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/reorientstruct\".\n",
      "180618-08:26:25,991 workflow INFO:\n",
      "\t [Node] Running \"reorientfunc\" (\"nipype.interfaces.fsl.utils.Reorient2Std\"), a CommandLine Interface with command:\n",
      "fslreorient2std /Users/catcamacho/Box/SNAP/BABIES/raw/021-BABIES/rest_raw.nii.gz /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/reorientfunc/rest_raw_reoriented.nii.gz\n",
      "180618-08:26:25,999 workflow INFO:\n",
      "\t [Node] Running \"reorientstruct\" (\"nipype.interfaces.fsl.utils.Reorient2Std\"), a CommandLine Interface with command:\n",
      "fslreorient2std /Users/catcamacho/Box/SNAP/BABIES/raw/021-BABIES/skullstripped_anat.nii.gz /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/reorientstruct/skullstripped_anat_reoriented.nii.gz\n",
      "180618-08:26:26,582 workflow INFO:\n",
      "\t [Node] Finished \"preprocwf.reorientstruct\".\n",
      "180618-08:26:27,910 workflow INFO:\n",
      "\t [Job 1] Completed (preprocwf.reorientstruct).\n",
      "180618-08:26:27,914 workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 1 jobs ready. Free memory (GB): 14.20/14.40, Free processors: 1/2.                     \n",
      "                     Currently running:\n",
      "                       * preprocwf.reorientfunc\n",
      "180618-08:26:27,984 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocwf.reslice_struct\" in \"/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/reslice_struct\".\n",
      "180618-08:26:28,5 workflow INFO:\n",
      "\t [Node] Running \"reslice_struct\" (\"nipype.interfaces.freesurfer.preprocess.MRIConvert\"), a CommandLine Interface with command:\n",
      "mri_convert --conform_size 2.0 --cropsize 128 128 128 --out_type nii --input_volume /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/reorientstruct/skullstripped_anat_reoriented.nii.gz --output_volume /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/reslice_struct/skullstripped_anat_reoriented_out.nii.gz\n",
      "180618-08:26:29,567 workflow INFO:\n",
      "\t [Node] Finished \"preprocwf.reorientfunc\".\n",
      "180618-08:26:29,911 workflow INFO:\n",
      "\t [Job 5] Completed (preprocwf.reorientfunc).\n",
      "180618-08:26:29,914 workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 1 jobs ready. Free memory (GB): 14.20/14.40, Free processors: 1/2.                     \n",
      "                     Currently running:\n",
      "                       * preprocwf.reslice_struct\n",
      "180618-08:26:29,984 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocwf.trimvols\" in \"/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/trimvols\".\n",
      "180618-08:26:29,996 workflow INFO:\n",
      "\t [Node] Running \"trimvols\" (\"nipype.interfaces.nipy.preprocess.Trim\")\n",
      "180618-08:26:31,455 workflow INFO:\n",
      "\t [Node] Finished \"preprocwf.trimvols\".\n",
      "180618-08:26:31,912 workflow INFO:\n",
      "\t [Job 6] Completed (preprocwf.trimvols).\n",
      "180618-08:26:31,915 workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 1 jobs ready. Free memory (GB): 14.20/14.40, Free processors: 1/2.                     \n",
      "                     Currently running:\n",
      "                       * preprocwf.reslice_struct\n",
      "180618-08:26:31,978 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocwf.slicetime_correct\" in \"/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/slicetime_correct\".\n",
      "180618-08:26:31,989 workflow INFO:\n",
      "\t [Node] Running \"slicetime_correct\" (\"nipype.interfaces.fsl.preprocess.SliceTimer\"), a CommandLine Interface with command:\n",
      "slicetimer --in=/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/trimvols/rest_raw_reoriented_trim.nii.gz --out=/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/slicetime_correct/rest_raw_reoriented_trim_st.nii.gz --direction=3 --repeat=2.500000\n",
      "180618-08:26:32,145 workflow INFO:\n",
      "\t [Node] Finished \"preprocwf.reslice_struct\".\n",
      "180618-08:26:33,912 workflow INFO:\n",
      "\t [Job 2] Completed (preprocwf.reslice_struct).\n",
      "180618-08:26:33,915 workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 1 jobs ready. Free memory (GB): 14.20/14.40, Free processors: 1/2.                     \n",
      "                     Currently running:\n",
      "                       * preprocwf.slicetime_correct\n",
      "180618-08:26:33,989 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocwf.reg_temp\" in \"/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/reg_temp\".\n",
      "180618-08:26:34,17 workflow INFO:\n",
      "\t [Node] Running \"reg_temp\" (\"nipype.interfaces.ants.registration.Registration\"), a CommandLine Interface with command:\n",
      "antsRegistration --float --collapse-output-transforms 1 --dimensionality 3 --initial-moving-transform [ /Users/catcamacho/Box/SNAP/BABIES/templates/T2w_BABIES_template_2mm.nii.gz, /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/reslice_struct/skullstripped_anat_reoriented_out.nii.gz, 1 ] --initialize-transforms-per-stage 0 --interpolation Linear --output [ transform, transform_Warped.nii.gz, transform_InverseWarped.nii.gz ] --transform Rigid[ 0.1 ] --metric Mattes[ /Users/catcamacho/Box/SNAP/BABIES/templates/T2w_BABIES_template_2mm.nii.gz, /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/reslice_struct/skullstripped_anat_reoriented_out.nii.gz, 1, 32, Regular, 0.25 ] --convergence [ 100x75x50, 1e-06, 10 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 4x2x1 --use-histogram-matching 0 --transform Affine[ 0.1 ] --metric Mattes[ /Users/catcamacho/Box/SNAP/BABIES/templates/T2w_BABIES_template_2mm.nii.gz, /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/reslice_struct/skullstripped_anat_reoriented_out.nii.gz, 1, 32, Regular, 0.25 ] --convergence [ 100x75x50, 1e-06, 10 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 4x2x1 --use-histogram-matching 0 --transform SyN[ 0.1, 3.0, 0.0 ] --metric CC[ /Users/catcamacho/Box/SNAP/BABIES/templates/T2w_BABIES_template_2mm.nii.gz, /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/reslice_struct/skullstripped_anat_reoriented_out.nii.gz, 1, 4, None, 1 ] --convergence [ 70x50x20, 1e-06, 10 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 4x2x1 --use-histogram-matching 0 --winsorize-image-intensities [ 0.005, 0.995 ]  --write-composite-transform 1\n",
      "180618-08:26:35,913 workflow INFO:\n",
      "\t [MultiProc] Running 2 tasks, and 0 jobs ready. Free memory (GB): 14.00/14.40, Free processors: 0/2.                     \n",
      "                     Currently running:\n",
      "                       * preprocwf.reg_temp\n",
      "                       * preprocwf.slicetime_correct\n",
      "180618-08:26:40,961 workflow INFO:\n",
      "\t [Node] Finished \"preprocwf.slicetime_correct\".\n",
      "180618-08:26:41,925 workflow INFO:\n",
      "\t [Job 7] Completed (preprocwf.slicetime_correct).\n",
      "180618-08:26:41,928 workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 2 jobs ready. Free memory (GB): 14.20/14.40, Free processors: 1/2.                     \n",
      "                     Currently running:\n",
      "                       * preprocwf.reg_temp\n",
      "180618-08:26:42,7 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocwf.get_FD\" in \"/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/get_FD\".\n",
      "180618-08:26:42,23 workflow INFO:\n",
      "\t [Node] Running \"get_FD\" (\"nipype.interfaces.fsl.utils.MotionOutliers\"), a CommandLine Interface with command:\n",
      "fsl_motion_outliers -i /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/slicetime_correct/rest_raw_reoriented_trim_st.nii.gz --fd -o rest_raw_reoriented_trim_st_outliers.txt -p motionplot.png -s FD.txt\n",
      "180618-08:26:43,926 workflow INFO:\n",
      "\t [MultiProc] Running 2 tasks, and 1 jobs ready. Free memory (GB): 14.00/14.40, Free processors: 0/2.                     \n",
      "                     Currently running:\n",
      "                       * preprocwf.get_FD\n",
      "                       * preprocwf.reg_temp\n",
      "180618-08:27:17,914 workflow INFO:\n",
      "\t [Node] Finished \"preprocwf.get_FD\".\n",
      "180618-08:27:17,954 workflow INFO:\n",
      "\t [Job 8] Completed (preprocwf.get_FD).\n",
      "180618-08:27:17,959 workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 1 jobs ready. Free memory (GB): 14.20/14.40, Free processors: 1/2.                     \n",
      "                     Currently running:\n",
      "                       * preprocwf.reg_temp\n",
      "180618-08:27:18,28 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocwf.motion_correct\" in \"/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/motion_correct\".\n",
      "180618-08:27:18,40 workflow INFO:\n",
      "\t [Node] Running \"motion_correct\" (\"nipype.interfaces.fsl.preprocess.MCFLIRT\"), a CommandLine Interface with command:\n",
      "mcflirt -in /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/slicetime_correct/rest_raw_reoriented_trim_st.nii.gz -meanvol -out /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/motion_correct/rest_raw_reoriented_trim_st_mcf.nii.gz -plots\n",
      "180618-08:27:19,958 workflow INFO:\n",
      "\t [MultiProc] Running 2 tasks, and 0 jobs ready. Free memory (GB): 14.00/14.40, Free processors: 0/2.                     \n",
      "                     Currently running:\n",
      "                       * preprocwf.motion_correct\n",
      "                       * preprocwf.reg_temp\n",
      "180618-08:27:59,85 workflow INFO:\n",
      "\t [Node] Finished \"preprocwf.motion_correct\".\n",
      "180618-08:28:00,0 workflow INFO:\n",
      "\t [Job 9] Completed (preprocwf.motion_correct).\n",
      "180618-08:28:00,3 workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 1 jobs ready. Free memory (GB): 14.20/14.40, Free processors: 1/2.                     \n",
      "                     Currently running:\n",
      "                       * preprocwf.reg_temp\n",
      "180618-08:28:00,87 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocwf.coregT2\" in \"/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/coregT2\".\n",
      "180618-08:28:00,118 workflow INFO:\n",
      "\t [Node] Running \"coregT2\" (\"nipype.interfaces.ants.registration.Registration\"), a CommandLine Interface with command:\n",
      "antsRegistration --float --collapse-output-transforms 1 --dimensionality 3 --initial-moving-transform [ /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/reslice_struct/skullstripped_anat_reoriented_out.nii.gz, /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/motion_correct/rest_raw_reoriented_trim_st_mcf.nii.gz, 1 ] --initialize-transforms-per-stage 0 --interpolation Linear --output [ transform, transform_Warped.nii.gz, transform_InverseWarped.nii.gz ] --transform Rigid[ 0.1 ] --metric Mattes[ /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/reslice_struct/skullstripped_anat_reoriented_out.nii.gz, /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/motion_correct/rest_raw_reoriented_trim_st_mcf.nii.gz, 1, 32, Regular, 0.25 ] --convergence [ 100x75x50, 1e-06, 10 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 4x2x1 --use-histogram-matching 0 --transform Affine[ 0.1 ] --metric Mattes[ /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/reslice_struct/skullstripped_anat_reoriented_out.nii.gz, /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/motion_correct/rest_raw_reoriented_trim_st_mcf.nii.gz, 1, 32, Regular, 0.25 ] --convergence [ 100x75x50, 1e-06, 10 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 4x2x1 --use-histogram-matching 0 --transform SyN[ 0.1, 3.0, 0.0 ] --metric CC[ /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/reslice_struct/skullstripped_anat_reoriented_out.nii.gz, /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/motion_correct/rest_raw_reoriented_trim_st_mcf.nii.gz, 1, 4, None, 1 ] --convergence [ 70x50x20, 1e-06, 10 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 4x2x1 --use-histogram-matching 0 --winsorize-image-intensities [ 0.005, 0.995 ]  --write-composite-transform 1\n",
      "180618-08:28:02,2 workflow INFO:\n",
      "\t [MultiProc] Running 2 tasks, and 0 jobs ready. Free memory (GB): 14.00/14.40, Free processors: 0/2.                     \n",
      "                     Currently running:\n",
      "                       * preprocwf.coregT2\n",
      "                       * preprocwf.reg_temp\n",
      "180618-09:01:54,727 workflow INFO:\n",
      "\t [Node] Finished \"preprocwf.reg_temp\".\n",
      "180618-09:01:55,645 workflow INFO:\n",
      "\t [Job 3] Completed (preprocwf.reg_temp).\n",
      "180618-09:01:55,648 workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 1 jobs ready. Free memory (GB): 14.20/14.40, Free processors: 1/2.                     \n",
      "                     Currently running:\n",
      "                       * preprocwf.coregT2\n",
      "180618-09:01:55,718 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocwf.segment\" in \"/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/segment\".\n",
      "180618-09:01:55,728 workflow INFO:\n",
      "\t [Node] Running \"segment\" (\"nipype.interfaces.fsl.preprocess.FAST\"), a CommandLine Interface with command:\n",
      "fast -N -n 3 -g -S 1 /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/segment/transform_Warped.nii.gz\n",
      "180618-09:01:57,653 workflow INFO:\n",
      "\t [MultiProc] Running 2 tasks, and 0 jobs ready. Free memory (GB): 14.00/14.40, Free processors: 0/2.                     \n",
      "                     Currently running:\n",
      "                       * preprocwf.segment\n",
      "                       * preprocwf.coregT2\n",
      "180618-09:02:05,888 workflow INFO:\n",
      "\t [Node] Finished \"preprocwf.segment\".\n",
      "180618-09:02:07,696 workflow INFO:\n",
      "\t [Job 4] Completed (preprocwf.segment).\n",
      "180618-09:02:07,699 workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 0 jobs ready. Free memory (GB): 14.20/14.40, Free processors: 1/2.                     \n",
      "                     Currently running:\n",
      "                       * preprocwf.coregT2\n",
      "180618-09:13:40,912 workflow INFO:\n",
      "\t [Node] Finished \"preprocwf.coregT2\".\n",
      "180618-09:13:42,103 workflow INFO:\n",
      "\t [Job 10] Completed (preprocwf.coregT2).\n",
      "180618-09:13:42,107 workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 2 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n",
      "180618-09:13:42,175 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocwf.applyT2xform\" in \"/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/applyT2xform\".\n",
      "180618-09:13:42,184 workflow INFO:\n",
      "\t [Node] Running \"applyT2xform\" (\"nipype.interfaces.ants.resampling.ApplyTransforms\"), a CommandLine Interface with command:\n",
      "antsApplyTransforms --default-value 0 --dimensionality 4 --float 0 --input /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/coregT2/transform_Warped.nii.gz --interpolation Linear --output transform_Warped_trans.nii.gz --reference-image /Users/catcamacho/Box/SNAP/BABIES/templates/T2w_BABIES_template_2mm.nii.gz --transform /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/coregT2/transformComposite.h5\n",
      "180618-09:13:42,184 workflow INFO:\n",
      "\t [Node] Setting-up \"preprocwf.make_coreg_img\" in \"/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/make_coreg_img\".\n",
      "180618-09:13:42,193 workflow INFO:\n",
      "\t [Node] Running \"make_coreg_img\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "180618-09:13:42,470 workflow WARNING:\n",
      "\t [Node] Error on \"preprocwf.applyT2xform\" (/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/applyT2xform)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180618-09:13:43,938 workflow DEBUG:\n",
      "\t Needed files: /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/make_coreg_img/coregistration.png;/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/make_coreg_img/_0xd0a9025a3857918c1bbf3a3bd3a2a1c8_unfinished.json;/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/make_coreg_img/_inputs.pklz;/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/make_coreg_img/_node.pklz\n",
      "180618-09:13:43,940 workflow DEBUG:\n",
      "\t Needed dirs: /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/make_coreg_img/_report\n",
      "180618-09:13:43,942 workflow DEBUG:\n",
      "\t Removing files: \n",
      "180618-09:13:43,948 workflow DEBUG:\n",
      "\t saved results in /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/make_coreg_img/result_make_coreg_img.pklz\n",
      "180618-09:13:43,950 workflow DEBUG:\n",
      "\t [Node] Writing post-exec report to \"/Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/make_coreg_img/_report/report.rst\"\n",
      "180618-09:13:43,955 workflow DEBUG:\n",
      "\t Aggregate: False\n",
      "180618-09:13:43,958 workflow INFO:\n",
      "\t [Node] Finished \"preprocwf.make_coreg_img\".\n",
      "180618-09:13:44,120 workflow ERROR:\n",
      "\t Node applyT2xform.a0 failed to run on host Cats-MacBook-Pro-2.local.\n",
      "180618-09:13:44,121 workflow ERROR:\n",
      "\t Saving crash info to /Users/catcamacho/Box/SNAP/BABIES/infant_rest/crash-20180618-091344-catcamacho-applyT2xform.a0-819faa10-89f3-4740-8bea-ef8fee92da33.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/nipype/pipeline/plugins/multiproc.py\", line 68, in run_node\n",
      "    result['result'] = node.run(updatehash=updatehash)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 480, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 564, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 644, in _run_command\n",
      "    result = self._interface.run(cwd=outdir)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/nipype/interfaces/base/core.py\", line 521, in run\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/nipype/interfaces/base/core.py\", line 1044, in _run_interface\n",
      "    self.raise_exception(runtime)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/nipype/interfaces/base/core.py\", line 981, in raise_exception\n",
      "    ).format(**runtime.dictcopy()))\n",
      "RuntimeError: Command:\n",
      "antsApplyTransforms --default-value 0 --dimensionality 4 --float 0 --input /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/coregT2/transform_Warped.nii.gz --interpolation Linear --output transform_Warped_trans.nii.gz --reference-image /Users/catcamacho/Box/SNAP/BABIES/templates/T2w_BABIES_template_2mm.nii.gz --transform /Users/catcamacho/Box/SNAP/BABIES/workflows/preprocwf/_subject_id_021/coregT2/transformComposite.h5\n",
      "Standard output:\n",
      "\n",
      "Standard error:\n",
      "\n",
      "Return code: 1\n",
      "\n",
      "180618-09:13:44,131 workflow INFO:\n",
      "\t [Job 16] Completed (preprocwf.make_coreg_img).\n",
      "180618-09:13:44,134 workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 0 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n",
      "180618-09:13:46,118 workflow INFO:\n",
      "\t ***********************************\n",
      "180618-09:13:46,120 workflow ERROR:\n",
      "\t could not run node: preprocwf.applyT2xform.a0\n",
      "180618-09:13:46,122 workflow INFO:\n",
      "\t crashfile: /Users/catcamacho/Box/SNAP/BABIES/infant_rest/crash-20180618-091344-catcamacho-applyT2xform.a0-819faa10-89f3-4740-8bea-ef8fee92da33.pklz\n",
      "180618-09:13:46,124 workflow INFO:\n",
      "\t ***********************************\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Workflow did not execute cleanly. Check log for details",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bb3b63eb3b4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mpreprocwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkflow_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mpreprocwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph2use\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'flat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mpreprocwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MultiProc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'n_procs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mproc_cores\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/nipype/pipeline/engine/workflows.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_report'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mdatestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%dT%H%M%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'write_provenance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/nipype/pipeline/plugins/base.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_node_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mreport_nodes_not_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# close any open resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/nipype/pipeline/plugins/tools.pyc\u001b[0m in \u001b[0;36mreport_nodes_not_run\u001b[0;34m(notrun)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***********************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         raise RuntimeError(('Workflow did not execute cleanly. '\n\u001b[0m\u001b[1;32m     82\u001b[0m                             'Check log for details'))\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Workflow did not execute cleanly. Check log for details"
     ]
    }
   ],
   "source": [
    "## Preprocessing Workflow\n",
    "\n",
    "# workflowname.connect([(node1,node2,[('node1output','node2input')]),\n",
    "#                    (node2,node3,[('node2output','node3input')])\n",
    "#                    ])\n",
    "\n",
    "preprocwf = Workflow(name='preprocwf')\n",
    "preprocwf.connect([(infosource,selectfiles,[('subject_id','subject_id')]), \n",
    "                   (selectfiles,reorientstruct,[('struct','in_file')]),\n",
    "                   (selectfiles,reorientfunc,[('func','in_file')]),\n",
    "                   (reorientstruct,reslice_struct,[('out_file','in_file')]),\n",
    "                   (reslice_struct,coregT2,[('out_file','fixed_image')]),\n",
    "                   (reorientfunc,trimvols,[('out_file','in_file')]),\n",
    "                   (trimvols,slicetime_correct,[('out_file','in_file')]),\n",
    "                   (slicetime_correct,motion_correct,[('slice_time_corrected_file','in_file')]),\n",
    "                   (slicetime_correct,get_FD,[('slice_time_corrected_file','in_file')]),\n",
    "                   (motion_correct,coregT2,[('out_file','moving_image')]),\n",
    "                   (motion_correct,art,[('par_file','realignment_parameters')]),\n",
    "                   (coregT2,make_coreg_img,[('warped_image','epi')]),\n",
    "                   (coregT2,applyT2xform,[('composite_transform','transforms')]),\n",
    "                   (coregT2, applyT2xform,[('warped_image','input_image')]),\n",
    "                   (applyT2xform, applyxform,[('output_image','input_image')]),\n",
    "                   (reslice_struct,make_coreg_img,[('out_file','anat')]),\n",
    "                   (applyxform,make_checkmask_img,[('output_image','epi')]),\n",
    "                   (reslice_struct,reg_temp,[('out_file','moving_image')]),\n",
    "                   (reg_temp,applyxform,[('composite_transform','transforms')]),\n",
    "                   (applyxform,gunzip,[('output_image','in_file')]),\n",
    "                   (gunzip,art,[('out_file','realigned_files')]),\n",
    "                   (reg_temp,segment,[('warped_image','in_files')]),\n",
    "                   \n",
    "                   (applyxform, datasink, [('output_image','preproc_func')]),\n",
    "                   (reg_temp, datasink,[('warped_image','preproc_anat')]),\n",
    "                   (get_FD, datasink, [('out_metric_values','FD_out_metric_values')]),\n",
    "                   (motion_correct,datasink,[('par_file','motion_params')]),\n",
    "                   (segment,datasink,[('tissue_class_files','tissue_class_files')]),\n",
    "                   (art,datasink, [('plot_files','art_plot_files')]),\n",
    "                   (art,datasink, [('outlier_files','vols_to_censor')]),\n",
    "                   (make_checkmask_img,datasink,[('maskcheck_file','maskcheck_image')]),\n",
    "                   (make_coreg_img,datasink,[('coreg_file','coreg_image')])                   \n",
    "                  ])\n",
    "preprocwf.base_dir = workflow_dir\n",
    "preprocwf.write_graph(graph2use='flat')\n",
    "preprocwf.run('MultiProc', plugin_args={'n_procs': proc_cores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resting state preprocessing\n",
    "# Identity node- select subjects\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                     name='infosource')\n",
    "infosource.iterables = ('subject_id', subjects_list)\n",
    "\n",
    "\n",
    "# Data grabber- select fMRI and sMRI\n",
    "templates = {'func': output_dir + '/masked_func/{subject_id}/rest_raw_reoriented_trim_st_mcf_flirt_masked.nii.gz',\n",
    "             'csf': output_dir + '/tissue_class_files/{subject_id}/skullstripped_anat_reoriented_resample_seg_0.nii.gz', \n",
    "             'vols_to_censor':output_dir + '/vols_to_censor/{subject_id}/art.rest_raw_reoriented_trim_st_mcf_flirt_masked_outliers.txt.gz', \n",
    "             'motion_params':output_dir + '/FD_out_metric_values/{subject_id}/FD.txt',\n",
    "             'wm':template_wm}\n",
    "selectfiles = Node(SelectFiles(templates), name='selectfiles')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Pull motion info for all subjects\n",
    "\n",
    "motion_df = DataFrame(columns=['meanFD','maxFD','NumCensoredVols'])\n",
    "\n",
    "if isdir(output_dir + '/motion_summary') ==False:\n",
    "    makedirs(output_dir + '/motion_summary')\n",
    "    \n",
    "motion_df_file = output_dir + '/motion_summary/motionSummary.csv'\n",
    "motion_df.to_csv(motion_df_file)\n",
    "\n",
    "def summarize_motion(motion_df_file, motion_file, vols_to_censor):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from os.path import dirname, basename\n",
    "    from numpy import asarray, mean\n",
    "    from pandas import DataFrame, Series, read_csv\n",
    "    \n",
    "    motion_df = read_csv(motion_df_file, index_col=0)\n",
    "    \n",
    "    motion = asarray(open(motion_file).read().splitlines()).astype(float)\n",
    "    censvols = open(vols_to_censor).read().splitlines()\n",
    "\n",
    "    fp = dirname(motion_file)\n",
    "    subject = basename(fp)\n",
    "\n",
    "    motion_df.loc[subject] = [mean(motion),max(motion),len(censvols)]\n",
    "    motion_df.to_csv(motion_df_file)\n",
    "\n",
    "    return()\n",
    "\n",
    "# Make a list of tissues for component noise removal\n",
    "def combine_masks(mask1,mask2):\n",
    "    from nipype.interfaces.fsl.utils import Merge\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    vols = []\n",
    "    vols.append(mask1)\n",
    "    vols.append(mask2)\n",
    "    \n",
    "    return(vols)\n",
    "    \n",
    "# Remove all noise (GLM with noise params)\n",
    "def create_noise_matrix(vols_to_censor,motion_params,comp_noise):\n",
    "    from numpy import genfromtxt, zeros,concatenate, savetxt\n",
    "    from os import path\n",
    "\n",
    "    motion = genfromtxt(motion_params, delimiter=' ', dtype=None, skip_header=0)\n",
    "    comp_noise = genfromtxt(comp_noise, delimiter='\\t', dtype=None, skip_header=1)\n",
    "    censor_vol_list = genfromtxt(vols_to_censor, delimiter='\\t', dtype=None, skip_header=0)\n",
    "\n",
    "    c = len(censor_vol_list)\n",
    "    d = len(comp_noise)\n",
    "    if c > 0:\n",
    "        scrubbing = zeros((d,c),dtype=int)\n",
    "        for t in range(0,c):\n",
    "            scrubbing[censor_vol_list[t]][t] = 1    \n",
    "        noise_matrix = concatenate([motion[:,None],comp_noise,scrubbing],axis=1)\n",
    "    else:\n",
    "        noise_matrix = concatenate((motion[:,None],comp_noise),axis=1)\n",
    "\n",
    "    noise_file = 'noise_matrix.txt'\n",
    "    savetxt(noise_file, noise_matrix, delimiter='\\t')\n",
    "    noise_filepath = path.abspath(noise_file)\n",
    "    \n",
    "    return(noise_filepath)\n",
    "\n",
    "def convertafni(in_file):\n",
    "    from nipype.interfaces.afni.utils import AFNItoNIFTI\n",
    "    from os import path\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    cvt = AFNItoNIFTI()\n",
    "    cvt.inputs.in_file = in_file\n",
    "    cvt.inputs.out_file = 'func_filtered.nii.gz'\n",
    "    cvt.run()\n",
    "    \n",
    "    out_file = path.abspath('func_filtered.nii.gz')\n",
    "    return(out_file)\n",
    "\n",
    "# Brightness threshold should be 0.75 * the contrast between the median brain intensity and the background\n",
    "def brightthresh(func):\n",
    "    import nibabel as nib\n",
    "    from numpy import median, where\n",
    "    \n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    func_nifti1 = nib.load(func)\n",
    "    func_data = func_nifti1.get_data()\n",
    "    func_data = func_data.astype(float)\n",
    "    \n",
    "    brain_values = where(func_data > 0)\n",
    "    median_thresh = median(brain_values)\n",
    "    bright_thresh = 0.75 * median_thresh\n",
    "    \n",
    "    return(bright_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Denoising\n",
    "merge_confs = Node(Function(input_names=['mask1','mask2'],\n",
    "                            output_names=['vols'], \n",
    "                            function=combine_masks), \n",
    "                   name='merge_confs')\n",
    "\n",
    "compcor = Node(CompCor(merge_method='none'), \n",
    "               name='compcor')\n",
    "\n",
    "noise_mat = Node(Function(input_names=['vols_to_censor','motion_params','comp_noise'],\n",
    "                          output_names=['noise_filepath'], \n",
    "                          function=create_noise_matrix), \n",
    "                 name='noise_mat')\n",
    "\n",
    "denoise = Node(GLM(out_res_name='denoised_residuals.nii', \n",
    "                   out_data_name='denoised_func.nii'), \n",
    "               name='denoise')\n",
    "\n",
    "# band pass filtering- all rates are in Hz (1/TR or samples/second)\n",
    "bandpass = Node(Bandpass(highpass=highpass_freq,\n",
    "                         lowpass=lowpass_freq), \n",
    "                name='bandpass')\n",
    "\n",
    "afni_convert = Node(Function(input_names=['in_file'],\n",
    "                             output_names=['out_file'],\n",
    "                             function=convertafni), \n",
    "                    name='afni_convert')\n",
    "\n",
    "# Spatial smoothing \n",
    "brightthresh_filt = Node(Function(input_names=['func'], \n",
    "                                  output_names=['bright_thresh'], \n",
    "                                  function=brightthresh), \n",
    "                         name='brightthresh_filt')    \n",
    "    \n",
    "smooth_filt = Node(SUSAN(fwhm=fwhm), name='smooth_filt')\n",
    "\n",
    "motion_summary = Node(Function(input_names=['motion_df_file','motion_file','vols_to_censor'], \n",
    "                               output_names=[], \n",
    "                               function=summarize_motion), \n",
    "                      name='motion_summary')\n",
    "motion_summary.inputs.motion_df_file = motion_df_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# workflowname.connect([(node1,node2,[('node1output','node2input')]),\n",
    "#                       (node2,node3,[('node2output','node3input')])\n",
    "#                     ])\n",
    "\n",
    "rs_procwf = Workflow(name='rs_procwf')\n",
    "rs_procwf.connect([(infosource,selectfiles,[('subject_id','subject_id')]),\n",
    "                   (selectfiles,compcor,[('func','realigned_file')]),\n",
    "                   (selectfiles,merge_confs,[('csf','mask1')]),\n",
    "                   (selectfiles,merge_confs,[('wm','mask2')]),\n",
    "                   (merge_confs,compcor,[('vols','mask_files')]),\n",
    "                   (compcor,noise_mat,[('components_file','comp_noise')]),\n",
    "                   (selectfiles,noise_mat,[('vols_to_censor','vols_to_censor'),\n",
    "                                           ('motion_params','motion_params')]),\n",
    "                   (noise_mat,denoise,[('noise_filepath','design')]),\n",
    "                   (selectfiles,denoise,[('func','in_file')]),\n",
    "                   (denoise,bandpass,[('out_data','in_file')]),\n",
    "                   (bandpass,afni_convert,[('out_file','in_file')]),\n",
    "                   (afni_convert,brightthresh_filt,[('out_file','func')]),\n",
    "                   (brightthresh_filt,smooth_filt,[('bright_thresh','brightness_threshold')]),\n",
    "                   (afni_convert,smooth_filt,[('out_file','in_file')]),  \n",
    "                   (selectfiles, motion_summary, [('motion_params','motion_file'),\n",
    "                                                  ('vols_to_censor','vols_to_censor')]),\n",
    "                   \n",
    "                   (register_template, datasink,[('out_file','preproc_struct')]),\n",
    "                   (smooth_filt,datasink,[('smoothed_file','preproc_func')])\n",
    "                   ])\n",
    "\n",
    "rs_procwf.base_dir = workflow_dir\n",
    "rs_procwf.write_graph(graph2use='flat')\n",
    "rs_procwf.run('MultiProc', plugin_args={'n_procs': proc_cores})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
