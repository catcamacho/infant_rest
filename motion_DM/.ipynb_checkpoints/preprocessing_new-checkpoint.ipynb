{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infant resting state fMRI preprocessing\n",
    "This notebook contains preprocessing tailored to infant resting state fMRI collected in 5-8 month olds. \n",
    "\n",
    "The processing steps for the fMRI broadly include:\n",
    "* Slice-time correction\n",
    "* Rigid realignment\n",
    "* Co-registration to the sMRI (T2-weighted structural MRI)\n",
    "* Co-registration to template\n",
    "* De-noising to remove:\n",
    "    - Mean timeseries for that voxel\n",
    "    - Component noise associated with white matter and CSF- delete the GM and smooth what is left\n",
    "    - motion regressors\n",
    "    - Motion derivatives (lagged 6 times)\n",
    "    - Squared derivatives (lagged 6 times) as an exploratory\n",
    "* Bandpass filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "from os import listdir, makedirs\n",
    "from os.path import isdir\n",
    "from nipype.interfaces.io import DataSink, SelectFiles, DataGrabber # Data i/o\n",
    "from nipype.interfaces.utility import IdentityInterface, Function     # utility\n",
    "from nipype.pipeline.engine import Node, Workflow, MapNode, JoinNode        # pypeline engine\n",
    "from nipype.interfaces.nipy.preprocess import Trim\n",
    "from nipype.interfaces.ants import N4BiasFieldCorrection\n",
    "from nipype.interfaces.fsl import SliceTimer, MCFLIRT, FLIRT, SUSAN, BET\n",
    "from nipype.interfaces.fsl.utils import Reorient2Std, MotionOutliers\n",
    "from nipype.interfaces.fsl.model import GLM\n",
    "from nipype.interfaces.fsl.maths import ApplyMask, MeanImage\n",
    "from nipype.interfaces.freesurfer import Resample, Binarize\n",
    "from nipype.algorithms.confounds import CompCor\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "#set output file type for FSL to NIFTI\n",
    "from nipype.interfaces.fsl.preprocess import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "# Set study variables\n",
    "studyhome = '/Users/catcamacho/Box/SNAP/BABIES'\n",
    "raw_data = studyhome + '/BABIES_rest/raw'\n",
    "output_dir = studyhome + '/BABIES_rest/processed/preproc'\n",
    "workflow_dir = studyhome + '/BABIES_rest/workflows'\n",
    "#subjects_list = open(studyhome + '/rest_misc/subjects.txt').read().splitlines()\n",
    "subjects_list = ['0002x','0010','0020','0023','0027','0032','0033x']\n",
    "\n",
    "template_brain = studyhome + '/templates/6mo_T2w_template_2mm.nii.gz'\n",
    "template_mask = studyhome + '/templates/6mo_T2w_template_2mm_mask.nii.gz'\n",
    "template_gmmask = studyhome + '/templates/6mo_T2w_template_2mm_gm.nii.gz' #need to update mask\n",
    "\n",
    "proc_cores = 2 # number of cores of processing for the workflows\n",
    "\n",
    "vols_to_trim = 4\n",
    "interleave = False\n",
    "TR = 2.5 # in seconds\n",
    "slice_dir = 3 # 1=x, 2=y, 3=z\n",
    "resampled_voxel_size = (2,2,2)\n",
    "fwhm = 4 #fwhm for smoothing with SUSAN\n",
    "\n",
    "mask_erosion = 1\n",
    "mask_dilation = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File handling Nodes\n",
    "\n",
    "# Identity node- select subjects\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                     name='infosource')\n",
    "infosource.iterables = ('subject_id', subjects_list)\n",
    "\n",
    "# Datasink- where our select outputs will go\n",
    "substitutions = [('_subject_id_', '')]\n",
    "datasink = Node(DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = output_dir\n",
    "datasink.inputs.container = output_dir\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess T2w anatomical images\n",
    "These nodes and workflow (anat_preprocflow) performs N4 bias correction and skullstripping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File handling nodes\n",
    "\n",
    "template={'anat': raw_data + '/%s/%s_T2w*.nii.gz'}\n",
    "selectfiles = Node(DataGrabber(sort_filelist=True,\n",
    "                               template = raw_data + '/%s/%s_T2w*.nii.gz',\n",
    "                               field_template = template,\n",
    "                               base_directory=raw_data,\n",
    "                               infields=['subject_id','subject_id2'],\n",
    "                               template_args={'anat':[['subject_id','subject_id2']]}),\n",
    "                   name='selectfiles')\n",
    "\n",
    "n4biascorr = Node(N4BiasFieldCorrection(dimension=3,\n",
    "                                        output_image='{0}_nucorrect.nii.gz'.format(anat_type)), \n",
    "                  name='n4biascorr')\n",
    "\n",
    "skullstrip = Node(BET(out_file='{0}_nucorrect_strip.nii.gz'.format(anat_type)), name='skullstrip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anat_preprocflow = Workflow(name='anat_preprocflow')\n",
    "anat_preprocflow.connect([(infosource,selectfiles, [('subject_id','subject_id')]),\n",
    "                          (infosource,selectfiles, [('subject_id','subject_id2')]),\n",
    "                          (selectfiles, n4biascorr, [('anat','input_image')]),\n",
    "                          (n4biascorr, skullstrip, [('output_image','in_file')]),\n",
    "                          \n",
    "                          (n4biascorr, datasink, [('output_image','nu_corrected_anat')]),\n",
    "                          (skullstrip, datasink, [('out_file','skullstripped_anat')])\n",
    "                         ])\n",
    "\n",
    "anat_preprocflow.base_dir = workflow_dir\n",
    "#anat_preprocflow.write_graph(graph2use='flat')\n",
    "anat_preprocflow.run('MultiProc', plugin_args={'n_procs': 2, 'memory_gb':10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess fMRI resting state data\n",
    "These nodes and workflow (preprocflow) perform basic preorpocessing to align the functional volumes into a common space.\n",
    "1. Reorient images to standard space\n",
    "2. Reslice the structural image to 2mm isotropic\n",
    "3. Functional image slice time correction\n",
    "4. Rigid realignment to first volume of functional image\n",
    "5. Coregistration of functional images to structural image\n",
    "6. Coregistration of functional images to template image\n",
    "7. Trim first 4 volumes of the functional images to remove pre-steady-state images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## File handling Nodes\n",
    "\n",
    "# Data grabber- select sMRI\n",
    "anat_template = {'struct': raw_data + '/{subject_id}/t2w_anat.nii.gz'}\n",
    "selectanat = Node(SelectFiles(anat_template), name='selectfiles')\n",
    "\n",
    "# Data grabber- select fMRI\n",
    "func_template = {'func':raw_data + '/%s/rest*.nii.gz'}\n",
    "selectfunc = Node(DataGrabber(sort_filelist=True,\n",
    "                              template = raw_data + '/%s/rest*.nii.gz',\n",
    "                              field_template = func_template,\n",
    "                              base_directory=raw_data,\n",
    "                              infields=['subject_id'], \n",
    "                              template_args={'func':[['subject_id']]}), name='selectfunc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nodes for preprocessing\n",
    "\n",
    "# Reorient to standard space using FSL\n",
    "reorientfunc = MapNode(Reorient2Std(), name='reorientfunc', iterfield=['in_file'])\n",
    "reorientstruct = Node(Reorient2Std(), name='reorientstruct')\n",
    "\n",
    "# Reslice- using MRI_convert \n",
    "reslice_struct = Node(Resample(voxel_size=resampled_voxel_size), name='reslice_struct')\n",
    "\n",
    "#Slice timing correction based on interleaved acquisition using FSL\n",
    "slicetime_correct = MapNode(SliceTimer(interleaved=interleave, \n",
    "                                       slice_direction=slice_dir,\n",
    "                                       time_repetition=TR),\n",
    "                            name='slicetime_correct', iterfield=['in_file'])\n",
    "# Rigid realignment\n",
    "realign = MapNode(MCFLIRT(save_plots=True), name='realign', iterfield=['in_file'])\n",
    "\n",
    "# Registration- using FLIRT\n",
    "# The BOLD image is 'in_file', the anat is 'reference', the output is 'out_file'\n",
    "firstvol = MapNode(Trim(end_index=1), name='firstvol',iterfield=['in_file'])\n",
    "coreg1 = MapNode(FLIRT(), name='coreg1', iterfield=['in_file'])\n",
    "coreg2 = MapNode(FLIRT(apply_xfm=True), name='coreg2', iterfield=['in_file','in_matrix_file'])\n",
    "\n",
    "# Registration\n",
    "register_template = Node(FLIRT(reference=template_brain, \n",
    "                               out_file='preproc_anat.nii.gz'), \n",
    "                         name='register_template')\n",
    "\n",
    "xfmFUNC = MapNode(FLIRT(reference=template_brain,apply_xfm=True), \n",
    "                  name='xfmFUNC', iterfield=['in_file'])\n",
    "\n",
    "trim = MapNode(Trim(begin_index=4), name='trim', iterfield=['in_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing Workflow\n",
    "\n",
    "preprocflow = Workflow(name='preprocflow')\n",
    "preprocflow.connect([(infosource,selectanat,[('subject_id','subject_id')]), \n",
    "                     (infosource,selectfunc,[('subject_id','subject_id')]), \n",
    "                     (selectanat,reorientstruct,[('struct','in_file')]),\n",
    "                     \n",
    "                     (reorientstruct,reslice_struct,[('out_file','in_file')]),\n",
    "                     (reslice_struct,coreg1,[('resampled_file','reference')]),\n",
    "                     (reslice_struct,coreg2,[('resampled_file','reference')]),\n",
    "                     (reslice_struct,register_template,[('resampled_file','in_file')]),\n",
    "                     \n",
    "                     (selectfunc,reorientfunc,[('func','in_file')]),\n",
    "                     (reorientfunc,slicetime_correct,[('out_file','in_file')]),\n",
    "                     (slicetime_correct, realign, [('slice_time_corrected_file','in_file')]),\n",
    "                     (realign,firstvol,[('out_file','in_file')]),\n",
    "                     (firstvol,coreg1,[('out_file','in_file')]),\n",
    "                     (realign,coreg2,[('out_file','in_file')]),\n",
    "                     (coreg1,coreg2,[('out_matrix_file', 'in_matrix_file')]),\n",
    "                     (register_template,xfmFUNC,[('out_matrix_file','in_matrix_file')]),\n",
    "                     (coreg2,xfmFUNC,[('out_file','in_file')]),\n",
    "                     (xfmFUNC,trim, [('out_file','in_file')]),\n",
    "                   \n",
    "                     (realign, datasink,[('par_file','motion_parameters')]),\n",
    "                     (register_template,datasink,[('out_file','proc_struct')]),\n",
    "                     (trim, datasink, [('out_file','registered_func')])\n",
    "                    ])\n",
    "preprocflow.base_dir = workflow_dir\n",
    "#preprocflow.write_graph(graph2use='flat')\n",
    "preprocflow.run('MultiProc', plugin_args={'n_procs': proc_cores})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Nuissance Regressors\n",
    "These nodes and workflow creates both the subject specific and general nuissance regressors needed for preprocessing the rest data per the process developed by David Montez. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data grabber- select fMRI\n",
    "funcs_template = {'funcs':output_dir + '/registered_func/*/*/rest*.nii.gz'}\n",
    "selectallfunc = Node(DataGrabber(sort_filelist=True,\n",
    "                              template = output_dir + '/registered_func/*/*/rest*.nii.gz',\n",
    "                              field_template = funcs_template,\n",
    "                              base_directory=output_dir,), name='selectallfunc')\n",
    "\n",
    "func_template = {'func':output_dir + '/registered_func/%s/*/rest*.nii.gz'}\n",
    "selectfunc = Node(DataGrabber(sort_filelist=True,\n",
    "                              template = output_dir + '/registered_func/%s/*/rest*.nii.gz',\n",
    "                              field_template = func_template,\n",
    "                              base_directory=output_dir,\n",
    "                              infields=['subject_id'], \n",
    "                              template_args={'func':[['subject_id']]}), name='selectfunc')\n",
    "\n",
    "# select motion params\n",
    "mot_template={'motion':output_dir + '/motion_parameters/%s/*/rest_reoriented_st_mcf.nii.gz.par'}\n",
    "select_motion = Node(DataGrabber(sort_filelist=True,\n",
    "                              template = output_dir + '/motion_parameters/%s/*/rest_reoriented_st_mcf.nii.gz.par',\n",
    "                              field_template = mot_template,\n",
    "                              base_directory=output_dir,\n",
    "                              infields=['subject_id'], \n",
    "                              template_args={'func':[['subject_id']]}), name='select_motion')\n",
    "\n",
    "# select sMRI\n",
    "struct_template = {'anat': output_dir + '/proc_struct/{subject_id}/preproc_anat.nii.gz'}\n",
    "selectanat = Node(SelectFiles(struct_template), name='selectanat')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_image_mean(in_files):\n",
    "    '''This function enables averaging across 4D acquisitions that are not exactly \n",
    "    the same length in the t direction (4th dimension).'''\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from os.path import abspath\n",
    "    from nibabel import load, save, Nifti1Image\n",
    "    import numpy as np\n",
    "    \n",
    "    image = load(in_files[0])\n",
    "    data = image.get_data()\n",
    "    data = np.expand_dims(data,4)\n",
    "\n",
    "    for a in range(1,len(files)):\n",
    "        tempimg = load(files[a])\n",
    "        tempdata = tempimg.get_data()\n",
    "        tempdata = np.expand_dims(tempdata,4)\n",
    "        if tempdata.shape[3] < data.shape[3]:\n",
    "            padn=data.shape[3]-tempdata.shape[3]\n",
    "            tempdata=np.pad(tempdata,pad_width=((0,0),(0,0),(0,0),(0,padn),(0,0)),\n",
    "                            mode='constant',constant_values=np.nan)\n",
    "        elif tempdata.shape[3] > data.shape[3]:\n",
    "            padn=tempdata.shape[3]-data.shape[3]\n",
    "            image = tempimg\n",
    "            tempdata=np.pad(data,pad_width=((0,0),(0,0),(0,0),(0,padn),(0,0)),\n",
    "                            mode='constant',constant_values=np.nan)\n",
    "        data = np.concatenate((data,tempdata),axis=4)\n",
    "    \n",
    "    mean_data = np.mean(data,axis=4,keepdims=False)\n",
    "    mean_img = Nifti1Image(mean_data, header=image.header,affine=image.affine)\n",
    "    \n",
    "    save(mean_img,'mean_func.nii.gz')\n",
    "    mean_file = abspath('mean_func.nii.gz')\n",
    "    return(mean_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# average whole sample timeseries\n",
    "avg_sample = JoinNode(Function(input_names=['in_files'], \n",
    "                              output_names=['mean_file'], \n",
    "                              function=multi_image_mean), \n",
    "                     name='avg_sample', \n",
    "                     joinfield=['in_files'], \n",
    "                      joinsource='infosource')\n",
    "\n",
    "#get principle components of scanner noise\n",
    "scanner_noise = Node(Function(input_names=['mean_file'],\n",
    "                              output_names=['component_noise'],\n",
    "                              function=afni3DmaskSVD),\n",
    "                     name='scanner_noise')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Denoise\n",
    "\n",
    "#remove scanner artifact\n",
    "denoise = Node(GLM(out_res_name='denoised_residuals.nii.gz', \n",
    "                   out_data_name='denoised_func.nii.gz'), \n",
    "               name='denoise')\n",
    "denoise.inputs.design = scanner_components\n",
    "\n",
    "mask_func = Node(ApplyMask(mask_file=template_mask), \n",
    "                 name='mask_func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "denoise_flow = Workflow(name='denoise_flow')\n",
    "denoise_flow.connect([(infosource, selectfiles,[('subject_id','subject_id')]),\n",
    "                      (selectfiles, denoise, [('func','in_file')]),\n",
    "                      (denoise, mask_func,[('out_res','in_file')]),\n",
    "                      \n",
    "                      (mask_func, datasink, [('out_file','denoised_func')])\n",
    "                     ])\n",
    "denoise_flow.base_dir = workflow_dir\n",
    "denoise_flow.write_graph(graph2use='flat')\n",
    "denoise_flow.run('MultiProc', plugin_args={'n_procs': proc_cores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identity node- select subjects\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                     name='infosource')\n",
    "infosource.iterables = ('subject_id', subjects_list)\n",
    "\n",
    "# Data grabber- select fMRI and sMRI\n",
    "templates = {'denoised_func': output_dir + '/denoised_func/{subject_id}/denoised_func_final.nii.gz'}\n",
    "selectfiles = Node(SelectFiles(templates), name='selectfiles')\n",
    "\n",
    "# Datasink- where our select outputs will go\n",
    "substitutions = [('_subject_id_', '')]\n",
    "datasink = Node(DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = output_dir\n",
    "datasink.inputs.container = output_dir\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data QC nodes\n",
    "def create_coreg_plot(epi,anat):\n",
    "    import os\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    \n",
    "    coreg_filename='coregistration.png'\n",
    "    display = plotting.plot_anat(epi, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'coregistration to anatomy')\n",
    "    display.add_edges(anat)\n",
    "    display.savefig(coreg_filename) \n",
    "    display.close()\n",
    "    coreg_file = os.path.abspath(coreg_filename)\n",
    "    \n",
    "    return(coreg_file)\n",
    "\n",
    "def check_mask_coverage(epi,brainmask):\n",
    "    import os\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    \n",
    "    maskcheck_filename='maskcheck.png'\n",
    "    display = plotting.plot_anat(epi, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'brainmask coverage')\n",
    "    display.add_contours(brainmask,levels=[.5], colors='r')\n",
    "    display.savefig(maskcheck_filename)\n",
    "    display.close()\n",
    "    maskcheck_file = os.path.abspath(maskcheck_filename)\n",
    "\n",
    "    return(maskcheck_file)\n",
    "\n",
    "make_coreg_img = Node(name='make_coreg_img',\n",
    "                      interface=Function(input_names=['epi','anat'],\n",
    "                                         output_names=['coreg_file'],\n",
    "                                         function=create_coreg_plot))\n",
    "\n",
    "make_checkmask_img = Node(name='make_checkmask_img',\n",
    "                      interface=Function(input_names=['epi','brainmask'],\n",
    "                                         output_names=['maskcheck_file'],\n",
    "                                         function=check_mask_coverage))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Pull motion info for all subjects\n",
    "\n",
    "motion_df_file = output_dir + '/motion_summary/motionSummary.csv'\n",
    "\n",
    "if isdir(output_dir + '/motion_summary') ==False:\n",
    "    makedirs(output_dir + '/motion_summary')\n",
    "    motion_df = DataFrame(columns=['meanFD','maxFD','NumCensoredVols'])\n",
    "    motion_df.to_csv(motion_df_file)\n",
    "\n",
    "def summarize_motion(motion_df_file, motion_file, vols_to_censor):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from os.path import dirname, basename\n",
    "    from numpy import asarray, mean\n",
    "    from pandas import DataFrame, Series, read_csv\n",
    "    \n",
    "    motion_df = read_csv(motion_df_file, index_col=0)\n",
    "    \n",
    "    motion = asarray(open(motion_file).read().splitlines()).astype(float)\n",
    "    censvols = open(vols_to_censor).read().splitlines()\n",
    "\n",
    "    fp = dirname(motion_file)\n",
    "    subject = basename(fp)\n",
    "\n",
    "    motion_df.loc[subject] = [mean(motion),max(motion),len(censvols)]\n",
    "    motion_df.to_csv(motion_df_file)\n",
    "\n",
    "    return()\n",
    "\n",
    "# Make a list of tissues for component noise removal\n",
    "def combine_masks(mask1,mask2):\n",
    "    from nipype.interfaces.fsl.utils import Merge\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    vols = []\n",
    "    vols.append(mask1)\n",
    "    vols.append(mask2)\n",
    "    \n",
    "    return(vols)\n",
    "    \n",
    "# Remove all noise (GLM with noise params)\n",
    "def create_noise_matrix(vols_to_censor,motion_params,comp_noise):\n",
    "    from numpy import genfromtxt, zeros,concatenate, savetxt\n",
    "    from os import path\n",
    "\n",
    "    motion = genfromtxt(motion_params, delimiter=' ', dtype=None, skip_header=0)\n",
    "    comp_noise = genfromtxt(comp_noise, delimiter='\\t', dtype=None, skip_header=1)\n",
    "    censor_vol_list = genfromtxt(vols_to_censor, delimiter='\\t', dtype=None, skip_header=0)\n",
    "\n",
    "    c = len(censor_vol_list)\n",
    "    d = len(comp_noise)\n",
    "    if c > 0:\n",
    "        scrubbing = zeros((d,c),dtype=int)\n",
    "        for t in range(0,c):\n",
    "            scrubbing[censor_vol_list[t]][t] = 1    \n",
    "        noise_matrix = concatenate([motion[:,None],comp_noise,scrubbing],axis=1)\n",
    "    else:\n",
    "        noise_matrix = concatenate((motion[:,None],comp_noise),axis=1)\n",
    "\n",
    "    noise_file = 'noise_matrix.txt'\n",
    "    savetxt(noise_file, noise_matrix, delimiter='\\t')\n",
    "    noise_filepath = path.abspath(noise_file)\n",
    "    \n",
    "    return(noise_filepath)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
