{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infant resting state fMRI preprocessing\n",
    "This notebook contains preprocessing tailored to infant resting state fMRI collected in 5-8 month olds. \n",
    "\n",
    "The processing steps for the fMRI broadly include:\n",
    "* Slice-time correction\n",
    "* Rigid realignment\n",
    "* Co-registration to the sMRI (T2-weighted structural MRI)\n",
    "* Artifact detection:\n",
    "    - Motion\n",
    "    - Global intensity outliers\n",
    "* De-noising to remove:\n",
    "    - Component noise associated with white matter and CSF\n",
    "    - component noise associated with motion\n",
    "    - Censoring/scrubbing of individual volumes detected as artifacts in the previous step\n",
    "    - Frame-wise displacement\n",
    "* Bandpass filtering\n",
    "* Spatial smoothing\n",
    "* Registration to infant sample template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "from os import listdir, makedirs\n",
    "from os.path import isdir\n",
    "from nipype.interfaces.io import DataSink, SelectFiles # Data i/o\n",
    "from nipype.interfaces.utility import IdentityInterface, Function     # utility\n",
    "from nipype.pipeline.engine import Node, Workflow, MapNode, JoinNode        # pypeline engine\n",
    "from nipype.interfaces.nipy.preprocess import Trim\n",
    "\n",
    "from nipype.interfaces.fsl.preprocess import SliceTimer, MCFLIRT, FLIRT, FAST, SUSAN\n",
    "from nipype.interfaces.fsl.utils import Reorient2Std, MotionOutliers\n",
    "from nipype.interfaces.fsl.model import GLM\n",
    "from nipype.interfaces.fsl.maths import ApplyMask,MeanImage\n",
    "from nipype.interfaces.freesurfer import Resample, Binarize\n",
    "from nipype.algorithms.confounds import CompCor\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "#set output file type for FSL to NIFTI\n",
    "from nipype.interfaces.fsl.preprocess import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "# Set study variables\n",
    "studyhome = '/Users/catcamacho/Box/SNAP/BABIES'\n",
    "#studyhome = '/Volumes/iang/active/BABIES/BABIES_rest'\n",
    "raw_data = studyhome + '/subjDir'\n",
    "output_dir = studyhome + '/processed/preproc'\n",
    "workflow_dir = studyhome + '/workflows'\n",
    "subjects_list = open(studyhome + '/rest_misc/subjects.txt').read().splitlines()\n",
    "#subjects_list = ['021-BABIES-T1']\n",
    "\n",
    "template_brain = studyhome + '/templates/T2w_BABIES_template_2mm.nii.gz'\n",
    "template_mask = studyhome + '/templates/T2w_BABIES_template_2mm_mask.nii.gz'\n",
    "template_wm = studyhome + '/templates/BABIES_wm_mask_2mm.nii.gz'\n",
    "\n",
    "proc_cores = 2 # number of cores of processing for the workflows\n",
    "\n",
    "vols_to_trim = 4\n",
    "interleave = False\n",
    "TR = 2.5 # in seconds\n",
    "slice_dir = 3 # 1=x, 2=y, 3=z\n",
    "resampled_voxel_size = (2,2,2)\n",
    "fwhm = 4 #fwhm for smoothing with SUSAN\n",
    "\n",
    "mask_erosion = 1\n",
    "mask_dilation = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## File handling Nodes\n",
    "\n",
    "# Identity node- select subjects\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                     name=\"infosource\")\n",
    "infosource.iterables = ('subject_id', subjects_list)\n",
    "\n",
    "\n",
    "# Data grabber- select fMRI and sMRI\n",
    "templates = {'struct': raw_data + '/{subject_id}/skullstripped_anat.nii.gz',\n",
    "            'func': raw_data + '/{subject_id}/rest_raw.nii.gz'}\n",
    "selectfiles = Node(SelectFiles(templates), name='selectfiles')\n",
    "\n",
    "# Datasink- where our select outputs will go\n",
    "substitutions = [('_subject_id_', '')]\n",
    "datasink = Node(DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = output_dir\n",
    "datasink.inputs.container = output_dir\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_image_mean(in_files):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from subprocess import call\n",
    "    from os.path import abspath\n",
    "    \n",
    "    out_name = 'mean_func'\n",
    "    data = ' '.join(in_files)\n",
    "    \n",
    "    call('3dMean','-prefix',out_name, data)\n",
    "    \n",
    "    mean_file = abspath('mean_func.nii.gz')\n",
    "    return(mean_file)\n",
    "\n",
    "def afni3DmaskSVD(mean_file):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from subprocess import call\n",
    "    \n",
    "    call()\n",
    "    \n",
    "    return(noise_components)\n",
    "\n",
    "def determine_trim(in_file, target_length):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from warnings import warn\n",
    "    from nibabel import load\n",
    "    \n",
    "    nii = load(in_file)\n",
    "    nii_data = nii.get_data()\n",
    "    t = nii_data.shape[3]\n",
    "    \n",
    "    if t > target_length:\n",
    "        vols_to_trim = t-target_length\n",
    "    elif t < target_length:\n",
    "        warn('Oh no! Target 4d nifti length is longer than file: ' + in_file)\n",
    "        vols_to_trim = 0\n",
    "    else:\n",
    "        vols_to_trim = 0\n",
    "    \n",
    "    return(vols_to_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nodes for preprocessing\n",
    "\n",
    "# Reorient to standard space using FSL\n",
    "reorientfunc = Node(Reorient2Std(), name='reorientfunc')\n",
    "reorientstruct = Node(Reorient2Std(), name='reorientstruct')\n",
    "\n",
    "# Reslice- using MRI_convert \n",
    "reslice_struct = Node(Resample(voxel_size=resampled_voxel_size), \n",
    "                       name='reslice_struct')\n",
    "\n",
    "#Slice timing correction based on interleaved acquisition using FSL\n",
    "slicetime_correct = Node(SliceTimer(interleaved=interleave, \n",
    "                                    slice_direction=slice_dir,\n",
    "                                   time_repetition=TR),\n",
    "                            name='slicetime_correct')\n",
    "\n",
    "# Motion correction- MEL\n",
    "motion_correct = Node(MCFLIRT(save_plots=True, \n",
    "                              mean_vol=True), \n",
    "                      name='motion_correct')\n",
    "\n",
    "# Get frame-wise displacement for each run: in_file; out_file, out_metric_plot, out_metric_values\n",
    "get_FD = Node(MotionOutliers(metric = 'fd',\n",
    "                             out_metric_values = 'FD.txt',\n",
    "                             out_metric_plot = 'motionplot.png',\n",
    "                             no_motion_correction=False),\n",
    "                 name='get_FD',)\n",
    "\n",
    "# Registration- using FLIRT\n",
    "# The BOLD image is 'in_file', the anat is 'reference', the output is 'out_file'\n",
    "coreg1 = Node(FLIRT(), name='coreg1')\n",
    "coreg2 = Node(FLIRT(apply_xfm=True), name = 'coreg2')\n",
    "\n",
    "# Registration\n",
    "register_template = Node(FLIRT(reference=template_brain, \n",
    "                               out_file='preproc_anat.nii.gz'), \n",
    "                         name='register_template')\n",
    "\n",
    "xfmFUNC = Node(FLIRT(reference=template_brain,apply_xfm=True), \n",
    "               name='xfmFUNC')\n",
    "\n",
    "\n",
    "# average whole sample timeseries\n",
    "avg_sample = JoinNode(Function(input_names=['in_files'], \n",
    "                              output_names=['mean_file'], \n",
    "                              function=multi_image_mean), \n",
    "                     name='avg_sample', \n",
    "                     joinfield=['in_files'], \n",
    "                      joinsource='infosource')\n",
    "\n",
    "#get principle components of scanner noise\n",
    "scanner_noise = Node(Function(input_names=['mean_file'],\n",
    "                              output_names=['component_noise'],\n",
    "                              function=afni3DmaskSVD),\n",
    "                     name='scanner_noise')\n",
    "\n",
    "# determine volumes to trim off end\n",
    "\n",
    "determine_trim.inputs.target_length = 141\n",
    "\n",
    "# trim the volumes\n",
    "trim = Node(Trim(out_file='preproc_func.nii.gz', \n",
    "                 end_index=140), \n",
    "            name='trim')\n",
    "\n",
    "#remove scanner artifact\n",
    "denoise = Node(GLM(out_res_name='denoised_residuals.nii.gz', \n",
    "                   out_data_name='denoised_func.nii.gz'), \n",
    "               name='denoise')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Preprocessing Workflow\n",
    "\n",
    "preprocwf = Workflow(name='preprocwf')\n",
    "preprocwf.connect([(infosource,selectfiles,[('subject_id','subject_id')]), \n",
    "                   (selectfiles,reorientstruct,[('struct','in_file')]),\n",
    "                   (selectfiles,reorientfunc,[('func','in_file')]),\n",
    "                   (reorientstruct,reslice_struct,[('out_file','in_file')]),\n",
    "                   (reslice_struct,coreg1,[('resampled_file','reference')]),\n",
    "                   (reslice_struct,coreg2,[('resampled_file','reference')]),\n",
    "                   (reorientfunc,slicetime_correct,[('out_file','in_file')]),\n",
    "                   (slicetime_correct,motion_correct,[('slice_time_corrected_file','in_file')]),\n",
    "                   (slicetime_correct,get_FD,[('slice_time_corrected_file','in_file')]),\n",
    "                   (motion_correct,coreg1,[('out_file','in_file')]),\n",
    "                   (motion_correct,coreg2,[('out_file','in_file')]),\n",
    "                   (coreg1, coreg2,[('out_matrix_file', 'in_matrix_file')]),\n",
    "                   (reslice_struct,register_template,[('resampled_file','in_file')]),\n",
    "                   (register_template, xfmFUNC,[('out_matrix_file','in_matrix_file')]),\n",
    "                   (coreg2,xfmFUNC,[('out_file','in_file')]),\n",
    "                   (xfmFUNC, trim, [('out_file','in_file')]),\n",
    "                   #(trim,avg_sample,[('out_file','in_files')]),\n",
    "                   #(avg_sample, scanner_noise, [('mean_file','mean_file')]),\n",
    "                   #(scanner_noise, denoise, [('component_noise','design')]),\n",
    "                   \n",
    "                   (get_FD, datasink, [('out_metric_values','FD_out_metric_values')]),\n",
    "                   (motion_correct,datasink,[('par_file','motion_params')]),\n",
    "                   (register_template,datasink,[('out_file','proc_struct')]),\n",
    "                   (trim, datasink, [('out_file','registered_func')])\n",
    "                   #(avg_sample, datasink, [('mean_file','group_avg_file')])\n",
    "                  ])\n",
    "preprocwf.base_dir = workflow_dir\n",
    "preprocwf.write_graph(graph2use='flat')\n",
    "preprocwf.run('MultiProc', plugin_args={'n_procs': proc_cores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resting state preprocessing\n",
    "scanner_components = output_dir + '/mean_func/mean_func_components.txt'\n",
    "\n",
    "# Identity node- select subjects\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                     name='infosource')\n",
    "infosource.iterables = ('subject_id', subjects_list)\n",
    "\n",
    "\n",
    "# Data grabber- select fMRI and sMRI\n",
    "templates = {'func': output_dir + '/registered_func/{subject_id}/preproc_func.nii.gz',\n",
    "             'motion_params':output_dir + '/FD_out_metric_values/{subject_id}/FD.txt'}\n",
    "selectfiles = Node(SelectFiles(templates), name='selectfiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoise\n",
    "\n",
    "#remove scanner artifact\n",
    "denoise = Node(GLM(out_res_name='denoised_residuals.nii.gz', \n",
    "                   out_data_name='denoised_func.nii.gz'), \n",
    "               name='denoise')\n",
    "denoise.inputs.design = scanner_components\n",
    "\n",
    "mask_func = Node(ApplyMask(mask_file=template_mask), \n",
    "                 name='mask_func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoise_flow = Workflow(name='denoise_flow')\n",
    "denoise_flow.connect([(infosource, selectfiles,[('subject_id','subject_id')]),\n",
    "                      (selectfiles, denoise, [('func','in_file')]),\n",
    "                      (denoise, mask_func,[('out_res','in_file')]),\n",
    "                      \n",
    "                      (mask_func, datasink, [('out_file','denoised_func')])\n",
    "                     ])\n",
    "denoise_flow.base_dir = workflow_dir\n",
    "denoise_flow.write_graph(graph2use='flat')\n",
    "denoise_flow.run('MultiProc', plugin_args={'n_procs': proc_cores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity node- select subjects\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                     name='infosource')\n",
    "infosource.iterables = ('subject_id', subjects_list)\n",
    "\n",
    "# Data grabber- select fMRI and sMRI\n",
    "templates = {'denoised_func': output_dir + '/denoised_func/{subject_id}/denoised_func_final.nii.gz'}\n",
    "selectfiles = Node(SelectFiles(templates), name='selectfiles')\n",
    "\n",
    "# Datasink- where our select outputs will go\n",
    "substitutions = [('_subject_id_', '')]\n",
    "datasink = Node(DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = output_dir\n",
    "datasink.inputs.container = output_dir\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brightness threshold should be 0.75 * the contrast between the median brain intensity and the background\n",
    "def brightthresh(func):\n",
    "    import nibabel as nib\n",
    "    from numpy import median, where\n",
    "    \n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    func_nifti1 = nib.load(func)\n",
    "    func_data = func_nifti1.get_data()\n",
    "    func_data = func_data.astype(float)\n",
    "    \n",
    "    brain_values = where(func_data > 0)\n",
    "    median_thresh = median(brain_values)\n",
    "    bright_thresh = 0.75 * median_thresh\n",
    "    \n",
    "    return(bright_thresh)\n",
    "\n",
    "# Spatial smoothing \n",
    "brightthresh = Node(Function(input_names=['func'], \n",
    "                             output_names=['bright_thresh'], \n",
    "                             function=brightthresh), \n",
    "                    name='brightthresh')    \n",
    "    \n",
    "smooth = Node(SUSAN(fwhm=fwhm,out_file='preproc_func.nii.gz'), name='smooth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_flow = Workflow(name='normal_flow')\n",
    "normal_flow.connect([(infosource, selectfiles, [('subject_id','subject_id')]),\n",
    "                     (selectfiles, brightthresh, [('denoised_func','func')]),\n",
    "                     (selectfiles, smooth, [('denoised_func','in_file')]),\n",
    "                     (brightthresh, smooth, [('bright_thresh','brightness_threshold')]),\n",
    "                     (smooth, datasink, [('smoothed_file','preproc_func')])\n",
    "                    ])\n",
    "normal_flow.base_dir = workflow_dir\n",
    "normal_flow.write_graph(graph2use='flat')\n",
    "normal_flow.run('MultiProc', plugin_args={'n_procs': proc_cores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data QC nodes\n",
    "def create_coreg_plot(epi,anat):\n",
    "    import os\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    \n",
    "    coreg_filename='coregistration.png'\n",
    "    display = plotting.plot_anat(epi, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'coregistration to anatomy')\n",
    "    display.add_edges(anat)\n",
    "    display.savefig(coreg_filename) \n",
    "    display.close()\n",
    "    coreg_file = os.path.abspath(coreg_filename)\n",
    "    \n",
    "    return(coreg_file)\n",
    "\n",
    "def check_mask_coverage(epi,brainmask):\n",
    "    import os\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    \n",
    "    maskcheck_filename='maskcheck.png'\n",
    "    display = plotting.plot_anat(epi, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'brainmask coverage')\n",
    "    display.add_contours(brainmask,levels=[.5], colors='r')\n",
    "    display.savefig(maskcheck_filename)\n",
    "    display.close()\n",
    "    maskcheck_file = os.path.abspath(maskcheck_filename)\n",
    "\n",
    "    return(maskcheck_file)\n",
    "\n",
    "make_coreg_img = Node(name='make_coreg_img',\n",
    "                      interface=Function(input_names=['epi','anat'],\n",
    "                                         output_names=['coreg_file'],\n",
    "                                         function=create_coreg_plot))\n",
    "\n",
    "make_checkmask_img = Node(name='make_checkmask_img',\n",
    "                      interface=Function(input_names=['epi','brainmask'],\n",
    "                                         output_names=['maskcheck_file'],\n",
    "                                         function=check_mask_coverage))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Pull motion info for all subjects\n",
    "\n",
    "motion_df = DataFrame(columns=['meanFD','maxFD','NumCensoredVols'])\n",
    "\n",
    "if isdir(output_dir + '/motion_summary') ==False:\n",
    "    makedirs(output_dir + '/motion_summary')\n",
    "    \n",
    "motion_df_file = output_dir + '/motion_summary/motionSummary.csv'\n",
    "motion_df.to_csv(motion_df_file)\n",
    "\n",
    "def summarize_motion(motion_df_file, motion_file, vols_to_censor):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from os.path import dirname, basename\n",
    "    from numpy import asarray, mean\n",
    "    from pandas import DataFrame, Series, read_csv\n",
    "    \n",
    "    motion_df = read_csv(motion_df_file, index_col=0)\n",
    "    \n",
    "    motion = asarray(open(motion_file).read().splitlines()).astype(float)\n",
    "    censvols = open(vols_to_censor).read().splitlines()\n",
    "\n",
    "    fp = dirname(motion_file)\n",
    "    subject = basename(fp)\n",
    "\n",
    "    motion_df.loc[subject] = [mean(motion),max(motion),len(censvols)]\n",
    "    motion_df.to_csv(motion_df_file)\n",
    "\n",
    "    return()\n",
    "\n",
    "# Make a list of tissues for component noise removal\n",
    "def combine_masks(mask1,mask2):\n",
    "    from nipype.interfaces.fsl.utils import Merge\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    vols = []\n",
    "    vols.append(mask1)\n",
    "    vols.append(mask2)\n",
    "    \n",
    "    return(vols)\n",
    "    \n",
    "# Remove all noise (GLM with noise params)\n",
    "def create_noise_matrix(vols_to_censor,motion_params,comp_noise):\n",
    "    from numpy import genfromtxt, zeros,concatenate, savetxt\n",
    "    from os import path\n",
    "\n",
    "    motion = genfromtxt(motion_params, delimiter=' ', dtype=None, skip_header=0)\n",
    "    comp_noise = genfromtxt(comp_noise, delimiter='\\t', dtype=None, skip_header=1)\n",
    "    censor_vol_list = genfromtxt(vols_to_censor, delimiter='\\t', dtype=None, skip_header=0)\n",
    "\n",
    "    c = len(censor_vol_list)\n",
    "    d = len(comp_noise)\n",
    "    if c > 0:\n",
    "        scrubbing = zeros((d,c),dtype=int)\n",
    "        for t in range(0,c):\n",
    "            scrubbing[censor_vol_list[t]][t] = 1    \n",
    "        noise_matrix = concatenate([motion[:,None],comp_noise,scrubbing],axis=1)\n",
    "    else:\n",
    "        noise_matrix = concatenate((motion[:,None],comp_noise),axis=1)\n",
    "\n",
    "    noise_file = 'noise_matrix.txt'\n",
    "    savetxt(noise_file, noise_matrix, delimiter='\\t')\n",
    "    noise_filepath = path.abspath(noise_file)\n",
    "    \n",
    "    return(noise_filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Denoising\n",
    "merge_confs = Node(Function(input_names=['mask1','mask2'],\n",
    "                            output_names=['vols'], \n",
    "                            function=combine_masks), \n",
    "                   name='merge_confs')\n",
    "\n",
    "compcor = Node(CompCor(merge_method='none'), \n",
    "               name='compcor')\n",
    "\n",
    "noise_mat = Node(Function(input_names=['vols_to_censor','motion_params','comp_noise'],\n",
    "                          output_names=['noise_filepath'], \n",
    "                          function=create_noise_matrix), \n",
    "                 name='noise_mat')\n",
    "\n",
    "motion_summary = Node(Function(input_names=['motion_df_file','motion_file','vols_to_censor'], \n",
    "                               output_names=[], \n",
    "                               function=summarize_motion), \n",
    "                      name='motion_summary')\n",
    "motion_summary.inputs.motion_df_file = motion_df_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# workflowname.connect([(node1,node2,[('node1output','node2input')]),\n",
    "#                       (node2,node3,[('node2output','node3input')])\n",
    "#                     ])\n",
    "\n",
    "rs_procwf = Workflow(name='rs_procwf')\n",
    "rs_procwf.connect([(infosource,selectfiles,[('subject_id','subject_id')]),\n",
    "                   (selectfiles,register_template,[('struct','in_file')]),\n",
    "                   (selectfiles,xfmFUNC,[('func','in_file')]),\n",
    "                   (selectfiles,xfmCSF,[('csf','in_file')]),\n",
    "                   (register_template, xfmFUNC,[('out_matrix_file','in_matrix_file')]),\n",
    "                   (register_template, xfmCSF,[('out_matrix_file','in_matrix_file')]),\n",
    "                   (xfmCSF,merge_confs,[('out_file','mask1')]),\n",
    "                   (selectfiles,merge_confs,[('wm','mask2')]),\n",
    "                   (merge_confs,compcor,[('vols','mask_files')]),\n",
    "                   (xfmFUNC,compcor,[('out_file','realigned_file')]),\n",
    "                   (compcor,noise_mat,[('components_file','comp_noise')]),\n",
    "                   (selectfiles,noise_mat,[('vols_to_censor','vols_to_censor'),\n",
    "                                           ('motion_params','motion_params')]),\n",
    "                   (noise_mat,denoise,[('noise_filepath','design')]),\n",
    "                   (xfmFUNC,denoise,[('out_file','in_file')]),\n",
    "                   (denoise,bandpass,[('out_data','in_file')]),\n",
    "                   (bandpass,afni_convert,[('out_file','in_file')]),\n",
    "                   (afni_convert,brightthresh_filt,[('out_file','func')]),\n",
    "                   (brightthresh_filt,smooth_filt,[('bright_thresh','brightness_threshold')]),\n",
    "                   (afni_convert,smooth_filt,[('out_file','in_file')]),  \n",
    "                   (selectfiles, motion_summary, [('motion_params','motion_file'),\n",
    "                                                  ('vols_to_censor','vols_to_censor')]),\n",
    "                   \n",
    "                   (register_template, datasink,[('out_file','preproc_struct')]),\n",
    "                   (smooth_filt,datasink,[('smoothed_file','preproc_func')])\n",
    "                   ])\n",
    "\n",
    "rs_procwf.base_dir = workflow_dir\n",
    "rs_procwf.write_graph(graph2use='flat')\n",
    "rs_procwf.run('MultiProc', plugin_args={'n_procs': proc_cores})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
