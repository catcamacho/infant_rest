{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infant resting state fMRI preprocessing\n",
    "This notebook contains preprocessing tailored to infant resting state fMRI collected in 5-8 month olds. \n",
    "\n",
    "The processing steps for the fMRI broadly include:\n",
    "* Slice-time correction\n",
    "* Rigid realignment\n",
    "* Co-registration to the sMRI (T2-weighted structural MRI)\n",
    "* Co-registration to template\n",
    "* De-noising to remove:\n",
    "    - Mean timeseries for that voxel\n",
    "    - Component noise associated with white matter and CSF- delete the GM and smooth what is left\n",
    "    - Component noise associated with background signal - delete brain and smooth what's left\n",
    "    - Component noise from the averaged timeseries\n",
    "    - motion regressors\n",
    "    - Motion derivatives (lagged 6 times)\n",
    "    - Squared derivatives (lagged 6 times) as an exploratory\n",
    "* Bandpass filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "from os import listdir, makedirs\n",
    "from os.path import isdir\n",
    "from nipype.interfaces.io import DataSink, SelectFiles, DataGrabber # Data i/o\n",
    "from nipype.interfaces.utility import IdentityInterface, Function     # utility\n",
    "from nipype.pipeline.engine import Node, Workflow, MapNode, JoinNode        # pypeline engine\n",
    "from nipype.interfaces.nipy.preprocess import Trim\n",
    "from nipype.interfaces.ants import N4BiasFieldCorrection\n",
    "from nipype.interfaces.fsl import SliceTimer, MCFLIRT, FLIRT, BET\n",
    "from nipype.interfaces.fsl.utils import Reorient2Std, MotionOutliers\n",
    "from nipype.interfaces.fsl.maths import ApplyMask, MeanImage\n",
    "from nipype.interfaces.freesurfer import Resample, Binarize\n",
    "from nipype.algorithms.confounds import CompCor\n",
    "from nipype.interfaces.afni.preprocess import Bandpass\n",
    "from nipype.interfaces.afni.utils import AFNItoNIFTI\n",
    "from pandas import DataFrame, Series,read_csv\n",
    "\n",
    "#set output file type for FSL to NIFTI_GZ\n",
    "from nipype.interfaces.fsl.preprocess import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "# MATLAB setup - Specify path to current SPM and the MATLAB's default mode\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('~/spm12/toolbox')\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "\n",
    "# Set study variables\n",
    "#studyhome = '/Users/catcamacho/Box/SNAP/BABIES'\n",
    "studyhome = '/home/camachocm2/Analysis/SNAP'\n",
    "raw_data = studyhome + '/raw'\n",
    "output_dir = studyhome + '/processed/preproc'\n",
    "workflow_dir = studyhome + '/workflows'\n",
    "subjects_info = read_csv(studyhome + '/misc/rest_subjects_info.csv',index_col=None, dtype={'subject_id':str})\n",
    "subjects_info['subject_id'] = subjects_info['subject_id'].apply(lambda x: x.zfill(4))\n",
    "subjects_list = subjects_info['subject_id'].tolist()\n",
    "\n",
    "template_brain = studyhome + '/templates/6mo_T2w_template_2mm.nii.gz'\n",
    "template_mask = studyhome + '/templates/6mo_T2w_template_2mm_mask.nii.gz'\n",
    "template_gmmask = studyhome + '/templates/6mo_T2w_template_2mm_gm.nii.gz'\n",
    "template_nongm = studyhome + '/templates/6mo_T2w_template_2mm_nongm.nii.gz'\n",
    "template_nonbrain = studyhome + '/templates/6mo_T2w_template_2mm_nonbrain.nii.gz'\n",
    "full_image = studyhome + '/templates/6mo_T2w_template_2mm_fullimage.nii.gz'\n",
    "\n",
    "proc_cores = 2 # number of cores of processing for the workflows\n",
    "\n",
    "vols_to_trim = 4\n",
    "interleave = False\n",
    "TR = 2.5 # in seconds\n",
    "slice_dir = 3 # 1=x, 2=y, 3=z\n",
    "resampled_voxel_size = (2,2,2)\n",
    "fwhm = 4 #fwhm for smoothing with SUSAN\n",
    "anat_type='t2'\n",
    "\n",
    "#changed to match Pendl et al 2017 (HBM)\n",
    "highpass_freq = 0.005 #in Hz\n",
    "lowpass_freq = 0.1 #in Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File handling Nodes\n",
    "\n",
    "# Identity node- select subjects\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                     name='infosource')\n",
    "infosource.iterables = ('subject_id', subjects_list)\n",
    "\n",
    "# Datasink- where our select outputs will go\n",
    "substitutions = [('_subject_id_', '')]\n",
    "datasink = Node(DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = output_dir\n",
    "datasink.inputs.container = output_dir\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess T2w anatomical images\n",
    "These nodes and workflow (anat_preprocflow) performs N4 bias correction and skullstripping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File handling nodes\n",
    "\n",
    "template={'anat': raw_data + '/%s*/t2w*.nii.gz'}\n",
    "selectfiles = Node(DataGrabber(sort_filelist=True,\n",
    "                               template = raw_data + '/%s*/t2w*.nii.gz',\n",
    "                               field_template = template,\n",
    "                               base_directory=raw_data,\n",
    "                               infields=['subject_id'],\n",
    "                               template_args={'anat':[['subject_id']]}),\n",
    "                   name='selectfiles')\n",
    "\n",
    "n4biascorr = Node(N4BiasFieldCorrection(dimension=3,\n",
    "                                        output_image='{0}_nucorrect.nii.gz'.format(anat_type)), \n",
    "                  name='n4biascorr')\n",
    "\n",
    "skullstrip = Node(BET(out_file='{0}_nucorrect_strip.nii.gz'.format(anat_type)), name='skullstrip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anat_preprocflow = Workflow(name='anat_preprocflow')\n",
    "anat_preprocflow.connect([(infosource,selectfiles, [('subject_id','subject_id')]),\n",
    "                          (selectfiles, n4biascorr, [('anat','input_image')]),\n",
    "                          (n4biascorr, skullstrip, [('output_image','in_file')]),\n",
    "                          \n",
    "                          (n4biascorr, datasink, [('output_image','nu_corrected_anat')]),\n",
    "                          (skullstrip, datasink, [('out_file','skullstripped_anat')])\n",
    "                         ])\n",
    "\n",
    "anat_preprocflow.base_dir = workflow_dir\n",
    "anat_preprocflow.write_graph(graph2use='flat')\n",
    "anat_preprocflow.run('MultiProc', plugin_args={'n_procs': 10, 'memory_gb':30})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess fMRI resting state data\n",
    "These nodes and workflow (preprocflow) perform basic preprocessing to align the functional volumes into a common space.\n",
    "1. Reorient images to standard space\n",
    "2. Reslice the structural image to 2mm isotropic\n",
    "3. Functional image slice time correction\n",
    "4. Rigid realignment to first volume of functional image\n",
    "5. Coregistration of functional images to structural image\n",
    "6. Coregistration of functional images to template image\n",
    "7. Trim first 4 volumes of the functional images to remove pre-steady-state images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## File handling Nodes\n",
    "\n",
    "# Data grabber- select sMRI\n",
    "anat_template = {'struct': output_dir + '/skullstripped_anat/{subject_id}/t2_nucorrect_strip.nii.gz'}\n",
    "selectanat = Node(SelectFiles(anat_template), name='selectfiles')\n",
    "\n",
    "# Data grabber- select fMRI\n",
    "func_template = {'func':raw_data + '/%s*/rest*.nii.gz'}\n",
    "selectfunc = Node(DataGrabber(sort_filelist=True,\n",
    "                              template = raw_data + '/%s*/rest*.nii.gz',\n",
    "                              field_template = func_template,\n",
    "                              base_directory=raw_data,\n",
    "                              infields=['subject_id'], \n",
    "                              template_args={'func':[['subject_id']]}), name='selectfunc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data QC nodes\n",
    "def create_coreg_plot(epi,anat):\n",
    "    import os\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    from nipype.interfaces.nipy.preprocess import Trim\n",
    "    from os.path import abspath\n",
    "    \n",
    "    tr = Trim()\n",
    "    tr.inputs.in_file = epi[0]\n",
    "    tr.inputs.end_index = 1\n",
    "    tr.inputs.out_file = 'firstvol.nii.gz'\n",
    "    tr.run()\n",
    "    \n",
    "    epi = abspath('firstvol.nii.gz')\n",
    "    \n",
    "    coreg_filename='coregistration.png'\n",
    "    display = plotting.plot_anat(epi, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'coregistration to anatomy')\n",
    "    display.add_edges(anat)\n",
    "    display.savefig(coreg_filename) \n",
    "    display.close()\n",
    "    coreg_file = os.path.abspath(coreg_filename)\n",
    "    \n",
    "    return(coreg_file)\n",
    "\n",
    "def check_mask_coverage(epi,brainmask):\n",
    "    import os\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    \n",
    "    from nipype.interfaces.nipy.preprocess import Trim\n",
    "    from os.path import abspath\n",
    "    \n",
    "    tr = Trim()\n",
    "    tr.inputs.in_file = epi[0]\n",
    "    tr.inputs.end_index = 1\n",
    "    tr.inputs.out_file = 'firstvol.nii.gz'\n",
    "    tr.run()\n",
    "    \n",
    "    epi = abspath('firstvol.nii.gz')\n",
    "    \n",
    "    maskcheck_filename='maskcheck.png'\n",
    "    display = plotting.plot_anat(epi, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'brainmask coverage')\n",
    "    display.add_contours(brainmask,levels=[.5], colors='r')\n",
    "    display.savefig(maskcheck_filename)\n",
    "    display.close()\n",
    "    maskcheck_file = os.path.abspath(maskcheck_filename)\n",
    "\n",
    "    return(maskcheck_file)\n",
    "\n",
    "make_coreg_img = Node(name='make_coreg_img',\n",
    "                      interface=Function(input_names=['epi','anat'],\n",
    "                                         output_names=['coreg_file'],\n",
    "                                         function=create_coreg_plot))\n",
    "\n",
    "make_checkmask_img = Node(name='make_checkmask_img',\n",
    "                      interface=Function(input_names=['epi','brainmask'],\n",
    "                                         output_names=['maskcheck_file'],\n",
    "                                         function=check_mask_coverage))\n",
    "\n",
    "make_checkmask_img.inputs.brainmask = template_gmmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nodes for preprocessing\n",
    "\n",
    "# Reorient to standard space using FSL\n",
    "reorientfunc = MapNode(Reorient2Std(), name='reorientfunc', iterfield=['in_file'])\n",
    "reorientstruct = Node(Reorient2Std(), name='reorientstruct')\n",
    "\n",
    "# Reslice- using MRI_convert \n",
    "reslice_struct = Node(Resample(voxel_size=resampled_voxel_size), name='reslice_struct')\n",
    "\n",
    "#Slice timing correction based on interleaved acquisition using FSL\n",
    "slicetime_correct = MapNode(SliceTimer(interleaved=interleave, \n",
    "                                       slice_direction=slice_dir,\n",
    "                                       time_repetition=TR, \n",
    "                                       out_file='st_func.nii.gz'),\n",
    "                            name='slicetime_correct', iterfield=['in_file'])\n",
    "# Rigid realignment\n",
    "realign = MapNode(MCFLIRT(save_plots=True,out_file='rest_moco.nii.gz'), name='realign', iterfield=['in_file'])\n",
    "\n",
    "# Registration- using FLIRT\n",
    "# The BOLD image is 'in_file', the anat is 'reference', the output is 'out_file'\n",
    "firstvol = MapNode(Trim(end_index=1), name='firstvol',iterfield=['in_file'])\n",
    "coreg1 = MapNode(FLIRT(), name='coreg1', iterfield=['in_file'])\n",
    "coreg2 = MapNode(FLIRT(apply_xfm=True), name='coreg2', iterfield=['in_file','in_matrix_file'])\n",
    "\n",
    "# Registration\n",
    "register_template = Node(FLIRT(reference=template_brain, \n",
    "                               out_file='preproc_anat.nii.gz'), \n",
    "                         name='register_template')\n",
    "\n",
    "xfmFUNC = MapNode(FLIRT(reference=template_brain,apply_xfm=True, out_file='realigned_func.nii.gz'), \n",
    "                  name='xfmFUNC', iterfield=['in_file'])\n",
    "\n",
    "trim = MapNode(Trim(begin_index=4, out_file='realigned_func.nii.gz'), name='trim', iterfield=['in_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing Workflow\n",
    "\n",
    "preprocflow = Workflow(name='preprocflow')\n",
    "preprocflow.connect([(infosource,selectanat,[('subject_id','subject_id')]), \n",
    "                     (infosource,selectfunc,[('subject_id','subject_id')]), \n",
    "                     (selectanat,reorientstruct,[('struct','in_file')]),\n",
    "                     \n",
    "                     (reorientstruct,reslice_struct,[('out_file','in_file')]),\n",
    "                     (reslice_struct,coreg1,[('resampled_file','reference')]),\n",
    "                     (reslice_struct,coreg2,[('resampled_file','reference')]),\n",
    "                     (reslice_struct,register_template,[('resampled_file','in_file')]),\n",
    "                     \n",
    "                     (selectfunc,reorientfunc,[('func','in_file')]),\n",
    "                     (reorientfunc,trim,[('out_file','in_file')]),\n",
    "                     (trim, slicetime_correct,[('out_file','in_file')]),\n",
    "                     (slicetime_correct, realign, [('slice_time_corrected_file','in_file')]),\n",
    "                     (realign,firstvol,[('out_file','in_file')]),\n",
    "                     (firstvol,coreg1,[('out_file','in_file')]),\n",
    "                     (realign,coreg2,[('out_file','in_file')]),\n",
    "                     (coreg1,coreg2,[('out_matrix_file', 'in_matrix_file')]),\n",
    "                     (register_template,xfmFUNC,[('out_matrix_file','in_matrix_file')]),\n",
    "                     (coreg2,xfmFUNC,[('out_file','in_file')]),\n",
    "                     \n",
    "                     (reorientstruct,make_coreg_img,[('out_file','anat')]),\n",
    "                     (coreg1,make_coreg_img,[('out_file','epi')]),\n",
    "                     (xfmFUNC,make_checkmask_img,[('out_file','epi')]),\n",
    "                     (make_checkmask_img,datasink,[('maskcheck_file','maskcheck_image')]),\n",
    "                     (make_coreg_img,datasink,[('coreg_file','coreg_image')]),\n",
    "                   \n",
    "                     (realign, datasink,[('par_file','motion_parameters')]),\n",
    "                     (register_template,datasink,[('out_file','proc_struct')]),\n",
    "                     (xfmFUNC, datasink, [('out_file','registered_func')])\n",
    "                    ])\n",
    "preprocflow.base_dir = workflow_dir\n",
    "preprocflow.write_graph(graph2use='flat')\n",
    "preprocflow.run('MultiProc', plugin_args={'n_procs': proc_cores})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Nuissance Regressors\n",
    "These nodes and workflow creates both the subject specific and general nuissance regressors needed for preprocessing the rest data per the process developed by David Montez. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data grabber- select fMRI\n",
    "func_template = {'func':output_dir + '/registered_func/%s/*/realigned_func.nii.gz'}\n",
    "selectfunc = Node(DataGrabber(sort_filelist = True,\n",
    "                              template = output_dir + '/registered_func/%s/*/realigned_func.nii.gz',\n",
    "                              field_template = func_template,\n",
    "                              base_directory = output_dir,\n",
    "                              infields=['subject_id'], \n",
    "                              template_args = {'func':[['subject_id']]}), name='selectfunc')\n",
    "\n",
    "# select motion params\n",
    "mot_template={'motion':output_dir + '/motion_parameters/%s/*/rest_moco.nii.gz.par'}\n",
    "selectmotion = Node(DataGrabber(sort_filelist = True,\n",
    "                                template = output_dir + '/motion_parameters/%s/*/rest_moco.nii.gz.par',\n",
    "                                field_template = mot_template,\n",
    "                                base_directory = output_dir,\n",
    "                                infields = ['subject_id'], \n",
    "                                template_args = {'motion':[['subject_id']]}), name='selectmotion')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mask_blur_func(mask, in_file):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from os.path import abspath\n",
    "    from numpy import median, where\n",
    "    from nipype.interfaces.fsl import ApplyMask, Smooth\n",
    "\n",
    "    applymask = ApplyMask()\n",
    "    applymask.inputs.mask_file = mask\n",
    "    applymask.inputs.in_file = in_file\n",
    "    applymask.inputs.out_file = 'masked_file.nii.gz'\n",
    "    applymask.inputs.nan2zeros = True\n",
    "    applymask.run()\n",
    "\n",
    "    masked_file = abspath('masked_file.nii.gz')\n",
    "\n",
    "    smooth = Smooth()\n",
    "    smooth.inputs.in_file = masked_file\n",
    "    smooth.inputs.fwhm = 4\n",
    "    smooth.inputs.smoothed_file = 'blurred_masked_file.nii.gz'\n",
    "    smooth.run()\n",
    "\n",
    "    blurred_masked_file = abspath('blurred_masked_file.nii.gz')\n",
    "\n",
    "    return(blurred_masked_file)\n",
    "\n",
    "def leadlagmatrix(motion_file):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from os.path import abspath\n",
    "    import numpy as np\n",
    "\n",
    "    motion_params = np.loadtxt(motion_file, dtype=float)\n",
    "    trs = motion_params.shape[0]\n",
    "    params = motion_params.shape[1]\n",
    "    leadlag = np.zeros((trs,params*6))\n",
    "    derivatives = np.gradient(motion_params, axis=0)\n",
    "    leadlagderivs = np.zeros((trs,params*6))\n",
    "    derivativessq = derivatives**2\n",
    "    leadlagderivssq = np.zeros((trs,params*6))\n",
    "\n",
    "    for i in range(0,params):\n",
    "        for j in range(0,6):\n",
    "            leadlag[:,j+params*i] =  np.roll(motion_params[:,i],shift=j, axis=0)\n",
    "            leadlag[:j,j+params*i] = 0\n",
    "\n",
    "    for i in range(0,params):\n",
    "        for j in range(0,6):\n",
    "            leadlagderivs[:,j+params*i] =  np.roll(derivatives[:,i],shift=j, axis=0)\n",
    "            leadlagderivs[:j,j+params*i] = 0\n",
    "\n",
    "    for i in range(0,params):\n",
    "        for j in range(0,6):\n",
    "            leadlagderivssq[:,j+params*i] =  np.roll(derivativessq[:,i],shift=j, axis=0)\n",
    "            leadlagderivssq[:j,j+params*i] = 0\n",
    "\n",
    "    np.savetxt('leadlag.txt', leadlag)\n",
    "    np.savetxt('derivsleadlag.txt', leadlagderivs)\n",
    "    np.savetxt('derivssqleadlag.txt', leadlagderivssq)\n",
    "\n",
    "    leadlagmot = abspath('leadlag.txt')\n",
    "    leadlagderivsmot = abspath('derivsleadlag.txt')\n",
    "    leadlagderivssqmot = abspath('derivssqleadlag.txt')\n",
    "    \n",
    "    return(leadlagmot, leadlagderivsmot, leadlagderivssqmot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get scanner noise\n",
    "session_noise = MapNode(Function(input_names=['mask','in_file'], \n",
    "                                 output_names=['blurred_masked_file'],\n",
    "                                 function=mask_blur_func), name='session_noise', iterfield=['in_file'])\n",
    "session_noise.inputs.mask=template_nonbrain\n",
    "\n",
    "# get noise associated with WM and CSF\n",
    "wmcsf_noise = MapNode(Function(input_names=['mask','in_file'], \n",
    "                               output_names=['blurred_masked_file'],\n",
    "                               function=mask_blur_func), name='wmcsf_noise', iterfield=['in_file'])\n",
    "wmcsf_noise.inputs.mask=template_nongm\n",
    "\n",
    "# extract components from session nifti\n",
    "comp_session_noise = MapNode(CompCor(repetition_time=TR,\n",
    "                                  num_components=9,\n",
    "                                  components_file='components.txt',\n",
    "                                  mask_files=full_image), \n",
    "                          name='comp_session_noise', iterfield=['realigned_file'])\n",
    "\n",
    "# extract components from WM-CSF nifti \n",
    "comp_wmcsf_noise = MapNode(CompCor(repetition_time=TR, \n",
    "                                   num_components=9,\n",
    "                                   components_file='components.txt',\n",
    "                                   mask_files=template_mask), \n",
    "                           name='comp_wmcsf_noise', iterfield=['realigned_file'])\n",
    "\n",
    "# prepare leadlag motion and derivatives\n",
    "prep_motion = MapNode(Function(input_names=['motion_file'], \n",
    "                               output_names=['leadlagmot','leadlagderivsmot','leadlagderivssqmot'],\n",
    "                               function=leadlagmatrix), \n",
    "                      name='prep_motion', iterfield=['motion_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_noise_flow = Workflow(name='create_noise_flow')\n",
    "create_noise_flow.connect([(infosource,selectfunc,[('subject_id','subject_id')]),\n",
    "                           (selectfunc, wmcsf_noise, [('func','in_file')]),\n",
    "                           (selectfunc, session_noise, [('func','in_file')]),\n",
    "                           (wmcsf_noise, comp_wmcsf_noise, [('blurred_masked_file','realigned_file')]),\n",
    "                           (session_noise, comp_session_noise, [('blurred_masked_file','realigned_file')]),\n",
    "                           (wmcsf_noise, datasink, [('blurred_masked_file','wmcsf_noise_file')]),\n",
    "                           (session_noise, datasink, [('blurred_masked_file','session_noise_file')]),\n",
    "                           (comp_wmcsf_noise, datasink, [('components_file','subject_wmcsf_comp_noise')]),\n",
    "                           (comp_session_noise, datasink, [('components_file','subject_session_comp_noise')]),\n",
    "                           \n",
    "                           (infosource,selectmotion,[('subject_id','subject_id')]),\n",
    "                           (selectmotion, prep_motion, [('motion','motion_file')]),\n",
    "                           (prep_motion, datasink, [('leadlagmot','leadlagmotion'),\n",
    "                                                    ('leadlagderivsmot','leadlagderivsmotion'),\n",
    "                                                    ('leadlagderivssqmot','leadlagderivs_squaremotion')])\n",
    "                          ])\n",
    "create_noise_flow.base_dir = workflow_dir\n",
    "create_noise_flow.write_graph(graph2use='flat')\n",
    "create_noise_flow.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191015-17:45:52,219 interface DEBUG:\n",
      "\t Performing polynomial regression on data of shape (113120, 152)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nipype.interfaces.base.support.InterfaceResult at 0x7fd32c6ff7f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "from nipype import config, logging\n",
    "config.enable_debug_mode()\n",
    "logging.update_logging(config)\n",
    "from os import mkdir, remove\n",
    "from os.path import abspath\n",
    "from nibabel import load, save, Nifti1Image\n",
    "import numpy as np\n",
    "from subprocess import check_call\n",
    "\n",
    "mkdir(output_dir + '/mean_func')\n",
    "mf_output_dir = output_dir + '/mean_func'\n",
    "\n",
    "in_files = glob(output_dir + '/registered_func/*/*/realigned_func.nii.gz')\n",
    "    \n",
    "image = load(in_files[0])\n",
    "data = image.get_data()\n",
    "data = np.expand_dims(data,4)\n",
    "maxt = data.shape[3]\n",
    "\n",
    "for a in range(1,len(in_files)):\n",
    "    tempimg = load(in_files[a])\n",
    "    tempdata = tempimg.get_data()\n",
    "    if tempdata.shape[3] > maxt:\n",
    "        maxt=tempdata.shape[3]\n",
    "\n",
    "files_to_avg = []        \n",
    "\n",
    "for a in range(0,len(in_files)):\n",
    "    tempimg = load(in_files[a])\n",
    "    tempdata = tempimg.get_data()\n",
    "    if tempdata.shape[3] < maxt:\n",
    "        padn=data.shape[3]-tempdata.shape[3]\n",
    "        tempdata=np.pad(tempdata,pad_width=((0,0),(0,0),(0,0),(0,padn)),\n",
    "                        mode='constant',constant_values=0)\n",
    "        new_img = Nifti1Image(tempdata, affine=tempimg.affine, header=tempimg.header)\n",
    "        save(new_img, 'realigned_func_pad_{0}.nii.gz'.format(a))\n",
    "        files_to_avg.append(abspath('realigned_func_pad_{0}.nii.gz'.format(a)))\n",
    "    elif tempdata.shape[3] == maxt:\n",
    "        files_to_avg.append(in_files[a])\n",
    "        \n",
    "mean_file=mf_output_dir+'/mean_funcs.nii.gz'\n",
    "\n",
    "check_call(['3dMean','-prefix',mean_file,'-non_zero'] +files_to_avg)\n",
    "\n",
    "# extract components from averaged time series\n",
    "comp_average_noise = CompCor()\n",
    "comp_average_noise.inputs.realigned_file=mean_file\n",
    "comp_average_noise.inputs.repetition_time=TR\n",
    "comp_average_noise.inputs.num_components=9\n",
    "comp_average_noise.inputs.components_file=mf_output_dir +'/components.txt' \n",
    "comp_average_noise.inputs.mask_files=template_mask\n",
    "comp_average_noise.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising Workflow\n",
    "\n",
    "The nodes and workflow below (denoise_flow) is designed to take the nuissance regressors created in the previous section (create_noise_flow) and perform voxel-specific denoising.  This is accomplished through the following steps:\n",
    "1. Voxel-specific denoising\n",
    "    - Create unique design matrix for each 3D voxel\n",
    "    - Perform a GLM for that voxel\n",
    "    - Project results back into 3D space\n",
    "2. Bandpass filtering [0.001:0.08]\n",
    "3. Concatenate and realign multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means_template={'mean_func': output_dir + '/mean_func/mean_funcs.nii.gz', \n",
    "                'mean_func_components': output_dir + '/mean_func/components.txt'}\n",
    "select_mean_noise = Node(SelectFiles(means_template), name='select_mean_noise')\n",
    "\n",
    "sub_files_template={'leadlagmotion': output_dir + '/leadlagmotion/{subject_id}/_prep_motion{runnum}/leadlag.txt', \n",
    "                    'leadlagderivsmotion': output_dir + '/leadlagderivsmotion/{subject_id}/_prep_motion{runnum}/derivsleadlag.txt', \n",
    "                    'leadlagderivs_squaremotion': output_dir + '/leadlagderivs_squaremotion/{subject_id}/_prep_motion{runnum}/derivssqleadlag.txt', \n",
    "                    'func': output_dir + '/registered_func/{subject_id}/_xfmFUNC{runnum}/realigned_func.nii.gz', \n",
    "                    'wmcsf': output_dir + '/subject_wmcsf_comp_noise/{subject_id}/_comp_wmcsf_noise{runnum}/components.txt', \n",
    "                    'session': output_dir + '/subject_session_comp_noise/{subject_id}/_comp_session_noise{runnum}/components.txt'}\n",
    "select_sub_files=Node(SelectFiles(sub_files_template),name='select_sub_files')\n",
    "select_sub_files.iterables=('runnum',['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def org_shared_noise(leadlagmotion, leadlagderivsmotion, leadlagderivs_squaremotion, wmcsf, session, mean_func_components):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from numpy import loadtxt, concatenate\n",
    "    from pandas import DataFrame\n",
    "    from os.path import abspath\n",
    "    \n",
    "    noise_list = []\n",
    "    for file in [leadlagmotion, leadlagderivsmotion, leadlagderivs_squaremotion]:\n",
    "        mo = loadtxt(file, dtype=float, comments=None)\n",
    "        length_of_file = mo.shape[0]\n",
    "        noise_list.append(mo)\n",
    "    for file in [wmcsf, session]:\n",
    "        mo = loadtxt(file,dtype=float, skiprows=1, comments=None)\n",
    "        length_of_file = mo.shape[0]\n",
    "        noise_list.append(mo)\n",
    "    \n",
    "    mean_func_noise = loadtxt(mean_func_components,skiprows=1, comments=None)\n",
    "    mean_func_noise_trim = mean_func_noise[:length_of_file,:]\n",
    "    noise_list.append(mean_func_noise_trim)\n",
    "    shared_noise_data = concatenate(noise_list,axis=1)\n",
    "    \n",
    "    col_names = ['noise_{0}'.format(a) for a in range(0,shared_noise_data.shape[1])] \n",
    "    \n",
    "    shared_noise = DataFrame(shared_noise_data, columns=col_names)\n",
    "    shared_noise.to_csv('shared_noise.csv')\n",
    "    shared_noise_file = abspath('shared_noise.csv')\n",
    "    return(shared_noise_file)\n",
    "\n",
    "def voxelwise_glm(func,shared_noise_file,mean_func,mask):\n",
    "    from os.path import abspath\n",
    "    from glm.glm import GLM\n",
    "    from glm.families import Gaussian\n",
    "    from numpy import zeros\n",
    "    from pandas import read_csv\n",
    "    from nilearn.masking import apply_mask, unmask\n",
    "    linear_model=GLM(family=Gaussian())\n",
    "\n",
    "    # import data into an array that is timepoints (rows) by voxel number (columns)\n",
    "    shared_noise = read_csv(shared_noise_file, index_col=0)\n",
    "    func_data = apply_mask(func, mask)\n",
    "    mean_func_data = apply_mask(mean_func, mask)\n",
    "    mean_func_data = mean_func_data[:func_data.shape[0],:]\n",
    "    coefficients = zeros((shared_noise.shape[1]+1,func_data.shape[1]))\n",
    "    residuals = zeros((func_data.shape))\n",
    "\n",
    "    # perform voxel-wise GLM\n",
    "    formula = 'signal ~ mean_signal' \n",
    "    for a in range(0,shared_noise.shape[1]-1):\n",
    "        formula = formula + ' + noise_{0}'.format(a)\n",
    "\n",
    "    for x in range(0,func_data.shape[1]):\n",
    "        shared_noise['mean_signal'] = mean_func_data[:,x]\n",
    "        shared_noise['signal'] = func_data[:,x]\n",
    "        linear_model.fit(shared_noise, formula=formula)\n",
    "        resid = shared_noise['signal']-linear_model.predict(shared_noise)\n",
    "        residuals[:,x] = resid\n",
    "        coefficients[:,x] = linear_model.coef_\n",
    "\n",
    "\n",
    "    coeff_image = unmask(coefficients, mask)\n",
    "    pval_image = unmask(pvals, mask)\n",
    "    resid_image = unmask(residuals, mask)\n",
    "    coeff_image.to_filename('weights.nii.gz')\n",
    "    resid_image.to_filename('resids.nii.gz')\n",
    "    sample_design_df = shared_noise.to_csv('last_noise_mat.csv')\n",
    "\n",
    "    weights = abspath('weights.nii.gz')\n",
    "    sample_design_df = abspath('last_noise_mat.csv')\n",
    "    denoised_func = abspath('resids.nii.gz')\n",
    "\n",
    "    return(weights,sample_design_df,denoised_func)\n",
    "\n",
    "def convertafni(in_file):\n",
    "    from nipype.interfaces.afni.utils import AFNItoNIFTI\n",
    "    from os import path\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    cvt = AFNItoNIFTI()\n",
    "    cvt.inputs.in_file = in_file\n",
    "    cvt.inputs.out_file = 'func_filtered.nii.gz'\n",
    "    cvt.run()\n",
    "    \n",
    "    out_file = path.abspath('func_filtered.nii.gz')\n",
    "    return(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_noise_mat = Node(Function(input_names=['leadlagmotion', 'leadlagderivsmotion', 'leadlagderivs_squaremotion', \n",
    "                                               'wmcsf', 'session', 'mean_func_components'],\n",
    "                                  output_names=['shared_noise_file'],\n",
    "                                  function=org_shared_noise), \n",
    "                         name='compile_noise_mat')\n",
    "\n",
    "denoise_func = Node(Function(input_names=['func','shared_noise_file','mean_func','mask'], \n",
    "                             output_names=['weights','sample_design_df','denoised_func'],\n",
    "                             function=voxelwise_glm),\n",
    "                    name='denoise_func')\n",
    "denoise_func.inputs.mask =template_gmmask\n",
    "\n",
    "# band pass filtering- all rates are in Hz (1/TR or samples/second)\n",
    "bandpass = Node(Bandpass(highpass=highpass_freq,\n",
    "                         lowpass=lowpass_freq), \n",
    "                name='bandpass')\n",
    "\n",
    "afni_convert = Node(Function(input_names=['in_file'],\n",
    "                             output_names=['out_file'],\n",
    "                             function=convertafni), \n",
    "                    name='afni_convert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "denoise_flow = Workflow(name='denoise_flow')\n",
    "denoise_flow.connect([(infosource, select_sub_files,[('subject_id','subject_id')]),\n",
    "                      (select_sub_files, denoise_func, [('func','func')]),\n",
    "                      (select_sub_files, compile_noise_mat, [('leadlagmotion','leadlagmotion'),\n",
    "                                                             ('leadlagderivsmotion','leadlagderivsmotion'), \n",
    "                                                             ('leadlagderivs_squaremotion','leadlagderivs_squaremotion'), \n",
    "                                                             ('wmcsf','wmcsf'), \n",
    "                                                             ('session','session')]),\n",
    "                      (compile_noise_mat, denoise_func, [('shared_noise_file','shared_noise_file')]),\n",
    "                      (denoise_func,bandpass,[('out_data','in_file')]),\n",
    "                      (bandpass,afni_convert,[('out_file','in_file')]),\n",
    "                      \n",
    "                      (select_mean_noise,compile_noise_mat,[('mean_func_components','mean_func_components')]),\n",
    "                      (select_mean_noise,denoise_func,[('mean_func','mean_func')]),\n",
    "                      \n",
    "                      (afni_convert,datasink,[('out_file','fully_processed_func')]),\n",
    "                      (denoise_func,datasink,[('weights','denoising_weights'),\n",
    "                                              ('sample_design_df','denoise_sample_design_df'),\n",
    "                                              ('denoised_func','denoised_func')]),\n",
    "                      \n",
    "                     ])\n",
    "denoise_flow.base_dir = workflow_dir\n",
    "denoise_flow.write_graph(graph2use='flat')\n",
    "denoise_flow.run('MultiProc', plugin_args={'n_procs': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadlagmotion='/home/camachocm2/Analysis/SNAP/processed/preproc/leadlagmotion/0122/_prep_motion0/leadlag.txt'\n",
    "leadlagderivsmotion='/home/camachocm2/Analysis/SNAP/processed/preproc/leadlagderivsmotion/0122/_prep_motion0/derivsleadlag.txt'\n",
    "leadlagderivs_squaremotion='/home/camachocm2/Analysis/SNAP/processed/preproc/leadlagderivs_squaremotion/0122/_prep_motion0/derivssqleadlag.txt'\n",
    "wmcsf='/home/camachocm2/Analysis/SNAP/processed/preproc/subject_wmcsf_comp_noise/0122/_comp_wmcsf_noise0/components.txt'\n",
    "session='/home/camachocm2/Analysis/SNAP/processed/preproc/subject_session_comp_noise/0122/_comp_session_noise0/components.txt'\n",
    "mean_func_components='/home/camachocm2/Analysis/SNAP/processed/preproc/mean_func/components.txt'\n",
    "\n",
    "shared_noise_file = org_shared_noise(leadlagmotion, leadlagderivsmotion, leadlagderivs_squaremotion, wmcsf, session, mean_func_components)\n",
    "func = '/home/camachocm2/Analysis/SNAP/processed/preproc/registered_func/0122/_xfmFUNC0/realigned_func.nii.gz'\n",
    "mean_func = '/home/camachocm2/Analysis/SNAP/processed/preproc/mean_func/mean_funcs.nii.gz'\n",
    "mask = '/home/camachocm2/Analysis/SNAP/templates/6mo_T2w_template_2mm_mask.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import abspath\n",
    "from glm.glm import GLM\n",
    "from glm.families import Gaussian\n",
    "from nilearn.masking import apply_mask, unmask\n",
    "linear_model=GLM(family=Gaussian())\n",
    "from numpy import zeros\n",
    "from numpy.linalg import inv\n",
    "from time import time\n",
    "from pandas import read_csv\n",
    "\n",
    "start = time()\n",
    "# import data into an array that is timepoints (rows) by voxel number (columns)\n",
    "shared_noise = read_csv(shared_noise_file, index_col=0)\n",
    "func_data = apply_mask(func, mask)\n",
    "mean_func_data = apply_mask(mean_func, mask)\n",
    "mean_func_data = mean_func_data[:func_data.shape[0],:]\n",
    "coefficients = zeros((shared_noise.shape[1]+1,func_data.shape[1]))\n",
    "\n",
    "# perform voxel-wise matrix inversion\n",
    "for x in range(0,func_data.shape[1]):\n",
    "    shared_noise['mean_signal'] = mean_func_data[:,x]\n",
    "    noise_mat = shared_noise.to_numpy()\n",
    "    inv_noise = inv(noise_mat)\n",
    "    y = func_data[:,x]\n",
    "    coefficients[:,x] = inv_noise*y\n",
    "    \n",
    "\n",
    "coeff_image = unmask(coefficients, mask)\n",
    "coeff_image.to_filename('weights.nii.gz')\n",
    "sample_design_df = shared_noise.to_csv('last_noise_mat.csv')\n",
    "\n",
    "weights = abspath('weights.nii.gz')\n",
    "sample_design_df = abspath('last_noise_mat.csv')\n",
    "finish = time()\n",
    "total_sec = finish-start\n",
    "total_hr = (total_sec/60)/60\n",
    "print('process took {0} seconds to run ({1} hours)'.format(round(total_sec,2), round(total_hr,2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
