{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "from os import listdir\n",
    "from nipype.interfaces.io import DataSink, SelectFiles, DataGrabber # Data i/o\n",
    "from nipype.interfaces.utility import IdentityInterface, Function     # utility\n",
    "from nipype.pipeline.engine import Node, Workflow, JoinNode        # pypeline engine\n",
    "\n",
    "from nipype.interfaces.fsl.model import Randomise, GLM, Cluster\n",
    "from nipype.interfaces.freesurfer.model import Binarize\n",
    "from nipype.interfaces.fsl.utils import ImageMeants, Merge, Split\n",
    "from nipype.interfaces.fsl.maths import ApplyMask\n",
    "\n",
    "#set output file type for FSL to NIFTI\n",
    "from nipype.interfaces.fsl.preprocess import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI')\n",
    "\n",
    "# MATLAB setup - Specify path to current SPM and the MATLAB's default mode\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('~/spm12')\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "\n",
    "# Set study variables\n",
    "studyhome = '/Users/catcamacho/Box/BABIES'\n",
    "raw_data = studyhome + '/raw'\n",
    "preproc_dir = studyhome + '/processed/preproc'\n",
    "output_dir = studyhome + '/processed/analysis2'\n",
    "workflow_dir = studyhome + '/workflows'\n",
    "roi_dir = studyhome + '/ROIs'\n",
    "group_con = studyhome + '/misc/tcon.con'\n",
    "group_mat = studyhome + '/misc/design.mat'\n",
    "proc_cores = 2\n",
    "\n",
    "#subjects_list = ['021-BABIES-T1','033x-BABIES-T1'] #listdir(raw_data)\n",
    "subjects_list = open(studyhome + '/misc/subjects.txt').read().splitlines()\n",
    "\n",
    "template_brain = studyhome + '/templates/T2w_BABIES_template_2mm.nii'\n",
    "\n",
    "# ROIs for connectivity analysis\n",
    "Lamyg = roi_dir + '/L_amyg_4mm.nii'\n",
    "Ramyg = roi_dir + '/R_amyg_4mm.nii'\n",
    "\n",
    "ROIs = [Lamyg, Ramyg]\n",
    "rois = ['L_amyg','R_amyg']\n",
    "\n",
    "min_clust_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## File handling\n",
    "# Identity node- select subjects\n",
    "infosource = Node(IdentityInterface(fields=['subject_id','ROIs']),\n",
    "                     name='infosource')\n",
    "infosource.iterables = [('subject_id', subjects_list),('ROIs',ROIs)]\n",
    "\n",
    "\n",
    "# Data grabber- select fMRI and ROIs\n",
    "templates = {'orig_func': preproc_dir + '/smoothed_filt_func/_subject_id_{subject_id}/func_filtered_smooth.nii'}\n",
    "selectfiles = Node(SelectFiles(templates), name='selectfiles')\n",
    "\n",
    "# Datasink- where our select outputs will go\n",
    "datasink = Node(DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = output_dir\n",
    "datasink.inputs.container = output_dir\n",
    "substitutions = [('_subject_id_', ''),\n",
    "                ('_ROIs_..Users..catcamacho..Box..BABIES..ROIs..','')]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Seed-based level 1\n",
    "\n",
    "# Extract ROI timeseries\n",
    "ROI_timeseries = Node(ImageMeants(), name='ROI_timeseries', iterfield='mask')\n",
    "\n",
    "def txt2vest(timeseries):\n",
    "    from os import system, path\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    vest = 'vest.mat'\n",
    "    system('Text2Vest '+ timeseries + ' ' + vest)\n",
    "    vest_file = path.abspath(vest)\n",
    "    return(vest_file)\n",
    "\n",
    "txt2vest = Node(name='txt2vest', \n",
    "                interface=Function(input_names=['timeseries'], \n",
    "                                   outputs_names=['vest_file'],\n",
    "                                   function=txt2vest))\n",
    "\n",
    "# model ROI connectivity\n",
    "glm = Node(GLM(out_file='betas.nii',out_cope='cope.nii'), name='glm', iterfield='design')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sbc1_workflow = Workflow(name='sbc1_workflow')\n",
    "sbc1_workflow.connect([(infosource,selectfiles,[('subject_id','subject_id')]),\n",
    "                       (selectfiles,ROI_timeseries,[('orig_func','in_file')]),\n",
    "                       (infosource,ROI_timeseries,[('ROIs','mask')]),\n",
    "                       (ROI_timeseries,glm,[('out_file','design')]),\n",
    "                       #(ROI_timeseries,txt2vest,[('out_file','timeseries')]),\n",
    "                       #(txt2vest,glm,[('vest_file','design')]),\n",
    "                       (selectfiles,glm,[('orig_func','in_file')]),\n",
    "                       (ROI_timeseries, datasink, [('out_file','roi_ts')]),\n",
    "                       (glm,datasink,[('out_cope','glm_seed_copes')]),\n",
    "                       (glm,datasink,[('out_file','glm_betas')])\n",
    "                      ])\n",
    "sbc1_workflow.base_dir = workflow_dir\n",
    "sbc1_workflow.write_graph(graph2use='flat')\n",
    "sbc1_workflow.run('MultiProc', plugin_args={'n_procs': proc_cores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infosource2 = Node(IdentityInterface(fields=['roi']),\n",
    "                   name='infosource2')\n",
    "infosource2.iterables = ('roi',rois)\n",
    "\n",
    "\n",
    "# Data grabber- select fMRI and ROIs\n",
    "templates = {'roi': 'glm_seed_copes/%s_4mm.nii*/cope.nii'}\n",
    "\n",
    "datagrabber = Node(DataGrabber(infields=['roi'], \n",
    "                               outfields=['roi'],\n",
    "                               sort_filelist=True,\n",
    "                               base_directory=output_dir,\n",
    "                               template='glm_seed_copes/%s_4mm.nii*/cope.nii',\n",
    "                               field_template=templates,\n",
    "                               template_args=dict(roi=[['roi']])),\n",
    "                   name='datagrabber')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Level 2\n",
    "\n",
    "# merge param estimates across all subjects per seed\n",
    "merge = Node(Merge(dimension='t'),\n",
    "             name='merge')\n",
    "\n",
    "# FSL randomise for higher level analysis\n",
    "highermodel = Node(Randomise(tfce=True,\n",
    "                             raw_stats_imgs= True,\n",
    "                             design_mat=group_mat,\n",
    "                             tcon=group_con),\n",
    "                   name = 'highermodel')\n",
    "\n",
    "## Cluster results\n",
    "\n",
    "# make binary masks of sig clusters\n",
    "binarize = Node(Binarize(min=0.95, max=1.0), \n",
    "                name='binarize', \n",
    "                iterfield='in_file')\n",
    "\n",
    "# mask T-map before clustering\n",
    "mask_tmaps = Node(ApplyMask(), name='mask_tmaps')\n",
    "\n",
    "# clusterize and extract cluster stats/peaks\n",
    "clusterize = Node(Cluster(threshold=3.5, \n",
    "                          out_index_file='outindex.nii', \n",
    "                          out_localmax_txt_file='localmax.txt'), \n",
    "                  name='clusterize')\n",
    "\n",
    "# make pictures if time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sbc2_workflow = Workflow(name='sbc2_workflow')\n",
    "sbc2_workflow.connect([(infosource2,datagrabber,[('roi','roi')]),\n",
    "                       (datagrabber,merge,[('roi','in_files')]),\n",
    "                       (merge,highermodel,[('merged_file','in_file')]),\n",
    "\n",
    "                       (highermodel,datasink,[('t_corrected_p_files','rand_corrp_files')]),\n",
    "                       (highermodel,datasink,[('tstat_files','rand_tstat_files')])\n",
    "                      ])\n",
    "sbc2_workflow.base_dir = workflow_dir\n",
    "sbc2_workflow.write_graph(graph2use='flat')\n",
    "sbc2_workflow.run('MultiProc', plugin_args={'n_procs': proc_cores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identity node- select subjects\n",
    "infosource3 = Node(IdentityInterface(fields=['roi']),\n",
    "                   name='infosource3')\n",
    "infosource3.iterables = [('roi',rois)]\n",
    "\n",
    "\n",
    "# Data grabber- select fMRI and ROIs\n",
    "templates = {'pcorrT': output_dir + '/rand_corrp_files/_roi_{roi}/tbss__tfce_corrp_tstat1.nii', \n",
    "             'tstat': output_dir + '/rand_tstat_files/_roi_{roi}/tbss__tstat1.nii'}\n",
    "selectfiles2 = Node(SelectFiles(templates), name='selectfiles2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sbc3_workflow = Workflow(name='sbc3_workflow')\n",
    "sbc3_workflow.connect([(infosource3,selectfiles2, [('roi','roi')]),\n",
    "                       (selectfiles2, binarize, [('pcorrT','in_file')]),\n",
    "                       (binarize, mask_tmaps, [('binary_file','mask_file')]),\n",
    "                       (selectfiles2, mask_tmaps, [('tstat','in_file')]),\n",
    "                       (mask_tmaps, clusterize, [('out_file','in_file')]),\n",
    "                       \n",
    "                       (binarize,datasink,[('binary_file','binary_pval')]),\n",
    "                       (mask_tmaps,datasink,[('out_file','masked_tmaps')]),\n",
    "                       (clusterize,datasink,[('index_file','cluster_index_file')]),\n",
    "                       (clusterize,datasink,[('localmax_txt_file','localmax_txt_file')])\n",
    "                      ])\n",
    "sbc3_workflow.base_dir = workflow_dir\n",
    "sbc3_workflow.write_graph(graph2use='flat')\n",
    "sbc3_workflow.run('MultiProc', plugin_args={'n_procs': proc_cores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identity node- select subjects\n",
    "infosource4 = Node(IdentityInterface(fields=['roi']),\n",
    "                   name='infosource4')\n",
    "infosource4.iterables = [('roi',rois)]\n",
    "\n",
    "\n",
    "# Data grabber- select fMRI and ROIs\n",
    "templates = {'clusters': output_dir + '/cluster_index_file/_roi_{roi}/outindex.nii', \n",
    "             'cluster_table': output_dir + '/localmax_txt_file/_roi_{roi}/cluster_table.txt'}\n",
    "selectfiles3 = Node(SelectFiles(templates), name='selectfiles3')\n",
    "\n",
    "# Grab betas for stuff\n",
    "templates2 = {'roi': 'glm_betas/%s_4mm.nii*-BABIES-T1/betas.nii'}\n",
    "\n",
    "betagrabber = Node(DataGrabber(infields=['roi'], \n",
    "                               outfields=['roi'],\n",
    "                               sort_filelist=True,\n",
    "                               base_directory=output_dir,\n",
    "                               template='glm_betas/%s_4mm.nii*-BABIES-T1/betas.nii',\n",
    "                               field_template=templates2,\n",
    "                               template_args=dict(roi=[['roi']])),\n",
    "                   name='betagrabber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parse clusters table\n",
    "def determine_clusters(clusters_table, min_clust_size):\n",
    "    from os import path\n",
    "    from numpy import genfromtxt\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    clusters = genfromtxt(clusters_table, delimiter='\\t', dtype=None, skip_header=1)\n",
    "    clusters_to_extract = []\n",
    "    \n",
    "    for t in clusters:\n",
    "        if clusters[t][1] >= min_clust_size:\n",
    "            clusters_to_extract.append(clusters[t][0])\n",
    "    \n",
    "    \n",
    "    return(cluster_index)\n",
    "\n",
    "det_clust = Node(name='det_clust', \n",
    "                 interface=Function(input_names=['clusters_table','min_clust_size'],\n",
    "                                    output_names=['cluster_index'], \n",
    "                                    function=determine_clusters))\n",
    "det_clust.inputs.min_clust_size=min_clust_size\n",
    "\n",
    "# separate cluster volumes\n",
    "split_clusters = Node(Split(dimension='t'), name='split_clusters')\n",
    "\n",
    "# merge betas together\n",
    "merge_betas = Node(Merge(dimension='t'), name='merge_betas')\n",
    "\n",
    "# extract betas for each subject/roi clusters\n",
    "extract_betas = Node(ImageMeants(),name='extract_betas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sbc4_workflow = Workflow(name='sbc4_workflow')\n",
    "sbc4_workflow.connect([(infosource4, selectfiles3, [('roi','roi')]),\n",
    "                       (infosource4, betagrabber, [('roi','roi')]),\n",
    "                       (selectfiles3, split_clusters, [('clusters','in_file')]),\n",
    "                       (betagrabber, merge_betas, [('roi','in_files')]),\n",
    "                       \n",
    "                       (merge_betas, datasink, [('merged_file','merged_betas')]),\n",
    "                       (split_clusters, datasink, [('out_files','split_clusters')])\n",
    "                      ])\n",
    "sbc4_workflow.base_dir = workflow_dir\n",
    "sbc4_workflow.write_graph(graph2use='flat')\n",
    "sbc4_workflow.run('MultiProc', plugin_args={'n_procs': proc_cores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
