{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "from os import listdir\n",
    "from nipype.interfaces.io import DataSink, SelectFiles # Data i/o\n",
    "from nipype.interfaces.utility import IdentityInterface, Function     # utility\n",
    "from nipype.pipeline.engine import Node, Workflow        # pypeline engine\n",
    "from nipype.interfaces.nipy.preprocess import Trim\n",
    "\n",
    "from nipype.algorithms.rapidart import ArtifactDetect \n",
    "from nipype.interfaces.fsl.preprocess import SliceTimer, MCFLIRT, FLIRT, FAST, SUSAN\n",
    "from nipype.interfaces.fsl.utils import Reorient2Std\n",
    "from nipype.interfaces.fsl.model import GLM\n",
    "from nipype.interfaces.fsl.maths import ApplyMask, TemporalFilter, \n",
    "from nipype.interfaces.freesurfer import Resample, Binarize\n",
    "from nipype.algorithms.confounds import CompCor\n",
    "\n",
    "#set output file type for FSL to NIFTI\n",
    "from nipype.interfaces.fsl.preprocess import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI')\n",
    "\n",
    "# MATLAB setup - Specify path to current SPM and the MATLAB's default mode\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('~/spm12')\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "\n",
    "# Set study variables\n",
    "studyhome = '/Users/catcamacho/Box/BABIES'\n",
    "raw_data = studyhome + '/raw'\n",
    "output_dir = studyhome + '/processed'\n",
    "workflow_dir = studyhome + '/workflows'\n",
    "subjects_list = ['021-BABIES-T1','033x-BABIES-T1'] #listdir(raw_data)\n",
    "\n",
    "template_brain = studyhome + '/templates/T2w_BABIES_template_2mm.nii'\n",
    "template_wm = studyhome + '/templates/WM_T2wreg_eroded.nii'\n",
    "\n",
    "vols_to_trim = 4\n",
    "interleave = False\n",
    "TR = 2 # in seconds\n",
    "slice_dir = 3 # 1=x, 2=y, 3=z\n",
    "proc_cores = 4 # number of cores of processing for the workflows\n",
    "resampled_voxel_size = (2,2,2)\n",
    "fwhm = 4 #fwhm for smoothing with SUSAN\n",
    "\n",
    "mask_erosion = 1\n",
    "mask_dilation = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## File handling Nodes\n",
    "\n",
    "# Identity node- select subjects\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                     name=\"infosource\")\n",
    "infosource.iterables = ('subject_id', subjects_list)\n",
    "\n",
    "\n",
    "# Data grabber- select fMRI and sMRI\n",
    "templates = {'struct': raw_data + '/{subject_id}/skullstripped_anat.nii',\n",
    "            'func': raw_data + '/{subject_id}/rest_raw.nii'}\n",
    "selectfiles = Node(SelectFiles(templates), name='selectfiles')\n",
    "\n",
    "# Datasink- where our select outputs will go\n",
    "datasink = Node(DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = output_dir\n",
    "datasink.inputs.container = output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Nodes for preprocessing\n",
    "\n",
    "# Reorient to standard space using FSL\n",
    "reorientfunc = Node(Reorient2Std(), name='reorientfunc')\n",
    "reorientstruct = Node(Reorient2Std(), name='reorientstruct')\n",
    "\n",
    "# Reslice- using MRI_convert \n",
    "reslice_struct = Node(Resample(voxel_size=resampled_voxel_size), \n",
    "                       name='reslice_struct')\n",
    "\n",
    "# Segment structural scan\n",
    "#segment = Node(Segment(affine_regularization='none'), name='segment')\n",
    "segment = Node(FAST(no_bias=True, \n",
    "                    segments=True, \n",
    "                    number_classes=3), \n",
    "               name='segment')\n",
    "\n",
    "# Trim first 4 volumes using nipype \n",
    "trimvols = Node(Trim(begin_index=vols_to_trim), name='trimvols')\n",
    "\n",
    "#Slice timing correction based on interleaved acquisition using FSL\n",
    "slicetime_correct = Node(SliceTimer(interleaved=interleave, \n",
    "                                    slice_direction=slice_dir,\n",
    "                                   time_repetition=TR),\n",
    "                            name='slicetime_correct')\n",
    "\n",
    "# Motion correction- MEL\n",
    "motion_correct = Node(MCFLIRT(save_plots=True, \n",
    "                              mean_vol=True), \n",
    "                      name='motion_correct')\n",
    "\n",
    "# Registration- using FLIRT\n",
    "# The BOLD image is 'in_file', the anat is 'reference', the output is 'out_file'\n",
    "coreg1 = Node(FLIRT(), name='coreg1')\n",
    "coreg2 = Node(FLIRT(apply_xfm=True), name = 'coreg2')\n",
    "\n",
    "# make binary mask \n",
    "# structural is the 'in_file', output is 'binary_file'\n",
    "binarize_struct = Node(Binarize(dilate=mask_dilation, \n",
    "                                erode=mask_erosion, \n",
    "                                min=1), \n",
    "                       name='binarize_struct')\n",
    "\n",
    "# apply the binary mask to the functional data\n",
    "# functional is 'in_file', binary mask is 'mask_file', output is 'out_file'\n",
    "mask_func = Node(ApplyMask(), name='mask_func')\n",
    "\n",
    "\n",
    "# Artifact detection for scrubbing/motion assessment\n",
    "art = Node(ArtifactDetect(mask_type='file',\n",
    "                          parameter_source='FSL',\n",
    "                          norm_threshold=1, #mutually exclusive with rotation and translation thresh\n",
    "                          zintensity_threshold=2,\n",
    "                          use_differences=[True, False]),\n",
    "           name='art')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data QC nodes\n",
    "def create_coreg_plot(epi,anat):\n",
    "    import os\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    \n",
    "    coreg_filename='coregistration.png'\n",
    "    display = plotting.plot_anat(epi, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'coregistration to anatomy')\n",
    "    display.add_edges(anat)\n",
    "    display.savefig(coreg_filename) \n",
    "    display.close()\n",
    "    coreg_file = os.path.abspath(coreg_filename)\n",
    "    \n",
    "    return(coreg_file)\n",
    "\n",
    "def check_mask_coverage(epi,brainmask):\n",
    "    import os\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nilearn import plotting\n",
    "    \n",
    "    maskcheck_filename='maskcheck.png'\n",
    "    display = plotting.plot_anat(epi, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'brainmask coverage')\n",
    "    display.add_contours(brainmask,levels=[.5], colors='r')\n",
    "    display.savefig(maskcheck_filename)\n",
    "    display.close()\n",
    "    maskcheck_file = os.path.abspath(maskcheck_filename)\n",
    "\n",
    "    return(maskcheck_file)\n",
    "\n",
    "make_coreg_img = Node(name='make_coreg_img',\n",
    "                      interface=Function(input_names=['epi','anat'],\n",
    "                                         output_names=['coreg_file'],\n",
    "                                         function=create_coreg_plot))\n",
    "\n",
    "make_checkmask_img = Node(name='make_checkmask_img',\n",
    "                      interface=Function(input_names=['epi','brainmask'],\n",
    "                                         output_names=['maskcheck_file'],\n",
    "                                         function=check_mask_coverage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Preprocessing Workflow\n",
    "\n",
    "# workflowname.connect([(node1,node2,[('node1output','node2input')]),\n",
    "#                    (node2,node3,[('node2output','node3input')])\n",
    "#                    ])\n",
    "\n",
    "preprocwf = Workflow(name='preprocwf')\n",
    "preprocwf.connect([(infosource,selectfiles,[('subject_id','subject_id')]), \n",
    "                   (selectfiles,reorientstruct,[('struct','in_file')]),\n",
    "                   (selectfiles,reorientfunc,[('func','in_file')]),\n",
    "                   (reorientstruct,reslice_struct,[('out_file','in_file')]),\n",
    "                   (reslice_struct,coreg1,[('resampled_file','reference')]),\n",
    "                   (reslice_struct,coreg2,[('resampled_file','reference')]),\n",
    "                   (reslice_struct,segment,[('resampled_file','in_files')]),\n",
    "                   (reorientfunc,trimvols,[('out_file','in_file')]),\n",
    "                   (trimvols,slicetime_correct,[('out_file','in_file')]),\n",
    "                   (slicetime_correct,motion_correct,[('slice_time_corrected_file','in_file')]),\n",
    "                   (motion_correct,coreg1,[('out_file','in_file')]),\n",
    "                   (motion_correct,coreg2,[('out_file','in_file')]),\n",
    "                   (coreg1, coreg2,[('out_matrix_file', 'in_matrix_file')]),\n",
    "                   (reslice_struct, binarize_struct, [('resampled_file','in_file')]),\n",
    "                   (binarize_struct,mask_func,[('binary_file','mask_file')]),\n",
    "                   (coreg2,mask_func,[('out_file','in_file')]),\n",
    "                   (mask_func,art,[('out_file','realigned_files')]),\n",
    "                   (binarize_struct,art,[('binary_file','mask_file')]),\n",
    "                   (motion_correct,art,[('par_file','realignment_parameters')]),\n",
    "                   (coreg1,make_coreg_img,[('out_file','epi')]),\n",
    "                   (reslice_struct,make_coreg_img,[('resampled_file','anat')]),\n",
    "                   (binarize_struct,make_checkmask_img,[('binary_file','brainmask')]),\n",
    "                   (coreg1,make_checkmask_img,[('out_file','epi')]),\n",
    "                   \n",
    "                   (motion_correct,datasink,[('par_file','motion_params')]),\n",
    "                   (reslice_struct,datasink,[('resampled_file','resliced_struct')]),\n",
    "                   (mask_func,datasink,[('out_file','masked_func')]),\n",
    "                   (segment,datasink,[('tissue_class_files','tissue_class_files')]),\n",
    "                   (art,datasink, [('plot_files','art_plot_files')]),\n",
    "                   (art,datasink, [('outlier_files','vols_to_censor')]),\n",
    "                   (make_checkmask_img,datasink,[('maskcheck_file','maskcheck_image')]),\n",
    "                   (make_coreg_img,datasink,[('coreg_file','coreg_image')])                   \n",
    "                  ])\n",
    "preprocwf.base_dir = workflow_dir\n",
    "preprocwf.write_graph(graph2use='flat')\n",
    "preprocwf.run('MultiProc', plugin_args={'n_procs': proc_cores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resting state preprocessing\n",
    "# Identity node- select subjects\n",
    "infosource = Node(IdentityInterface(fields=['subject_id','fwhm']),\n",
    "                     name='infosource')\n",
    "infosource.iterables = ('subject_id', subjects_list)\n",
    "\n",
    "\n",
    "# Data grabber- select fMRI and sMRI\n",
    "templates = {'struct': output_dir + '/resliced_struct/_subject_id_{subject_id}/skullstripped_anat_reoriented_resample.nii',\n",
    "             'func': output_dir + '/masked_func/_subject_id_{subject_id}/rest_raw_reoriented_trim_st_mcf_flirt_masked.nii',\n",
    "             'csf': output_dir + '/tissue_class_files/_subject_id_{subject_id}/skullstripped_anat_reoriented_resample_seg_0.nii', \n",
    "             'vols_to_censor':output_dir + '/vols_to_censor/_subject_id_{subject_id}/art.rest_raw_reoriented_trim_st_mcf_flirt_masked_outliers.txt', \n",
    "             'motion_params':output_dir + '/motion_params/_subject_id_{subject_id}/rest_raw_reoriented_trim_st_mcf.nii.par',\n",
    "             'wm':template_wm}\n",
    "selectfiles = Node(SelectFiles(templates), name='selectfiles')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "register_template = Node(FLIRT(reference=template_brain), \n",
    "                         name='register_template')\n",
    "xfmCSF = Node(FLIRT(reference=template_brain,apply_xfm=True), \n",
    "              name='xfmCSF')\n",
    "xfmFUNC = Node(FLIRT(reference=template_brain,apply_xfm=True), \n",
    "               name='xfmFUNC')\n",
    "\n",
    "def combine_masks(mask1,mask2):\n",
    "    from nipype.interfaces.fsl.utils import Merge\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    vols = []\n",
    "    vols.append(mask1)\n",
    "    vols.append(mask2)\n",
    "    \n",
    "    return(vols)\n",
    "    \n",
    "merge_confs = Node(name='merge_confs', interface=Function(input_names=['mask1','mask2'], \n",
    "                                                          output_names=['vols'], \n",
    "                                                          function=combine_masks))\n",
    "\n",
    "compcor = Node(CompCor(merge_method='none'), \n",
    "               name='compcor')\n",
    "\n",
    "\n",
    "# Remove all noise (GLM with noise params)\n",
    "def create_noise_matrix(vols_to_censor,motion_params,comp_noise):\n",
    "    from numpy import genfromtxt, zeros,concatenate\n",
    "    motion = genfromtxt(motion_params, delimiter='  ', dtype=None, skip_header=0)\n",
    "    comp_noise = genfromtxt(comp_noise, delimiter='\\t', dtype=None, skip_header=1)\n",
    "    censor_vol_list = genfromtxt(vols_to_censor, delimiter='\\t', dtype=None, skip_header=0)\n",
    "    \n",
    "    c = len(censor_vol_list)\n",
    "    d = len(comp_noise)\n",
    "    if c > 0:\n",
    "        scrubbing = zeros((d,c),dtype=int)\n",
    "        for t in range(c):\n",
    "            scrubbing[censor_vol_list[t]][t] = 1\n",
    "        noise_matrix = concatenate((motion,comp_noise,scrubbing),axis=1)\n",
    "    else:\n",
    "        noise_matrix = concatenate((motion,comp_noise),axis=1)\n",
    "        \n",
    "    return(noise_matrix)\n",
    "\n",
    "noise_mat = Node(name='noise_mat', interface=Function(input_names=['vols_to_censor','motion_params','comp_noise'],\n",
    "                                                      output_names=['noise_matrix'], \n",
    "                                                      function=create_noise_matrix))\n",
    "\n",
    "denoise = Node(GLM(), name='denoise')\n",
    "\n",
    "# AR filter- We'll need to play with this a bit for newborns- not super necessary right now. \n",
    "\n",
    "# band pass filtering\n",
    "bandpass = Node(TemporalFilter(), name='bandpass')\n",
    "\n",
    "# Spatial smoothing using FSL\n",
    "# Brightness threshold should be 0.75 * the contrast between the median brain intensity and the background\n",
    "def brightthresh(func):\n",
    "    import nibabel as nib\n",
    "    from numpy import median, where\n",
    "    \n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    func_nifti1 = nib.load(func)\n",
    "    func_data = func_nifti1.get_data()\n",
    "    func_data = func_data.astype(float)\n",
    "    \n",
    "    brain_values = where(func_data > 0)\n",
    "    median_thresh = median(brain_values)\n",
    "    bright_thresh = 0.75 * median_thresh\n",
    "    \n",
    "    return(bright_thresh)\n",
    "\n",
    "brightthresh = Node(name='brightthresh', \n",
    "                    interface=Function(input_names=['func'], \n",
    "                                       output_names=['bright_thresh'], \n",
    "                                       function=brightthresh))    \n",
    "    \n",
    "smooth = Node(SUSAN(), name='smooth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170716-12:11:39,533 workflow INFO:\n",
      "\t Generated workflow graph: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/graph.dot.png (graph2use=flat, simple_form=True).\n",
      "170716-12:11:39,567 workflow INFO:\n",
      "\t Workflow rs_procwf settings: ['check', 'execution', 'logging']\n",
      "170716-12:11:39,610 workflow INFO:\n",
      "\t Running in parallel.\n",
      "170716-12:11:39,617 workflow INFO:\n",
      "\t Executing: selectfiles.a0 ID: 0\n",
      "170716-12:11:39,620 workflow INFO:\n",
      "\t Executing: selectfiles.a1 ID: 1\n",
      "170716-12:11:39,623 workflow INFO:\n",
      "\t Executing node selectfiles.a0 in dir: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/selectfiles\n",
      "170716-12:11:39,627 workflow INFO:\n",
      "\t Executing node selectfiles.a1 in dir: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/selectfiles\n",
      "170716-12:11:39,660 workflow INFO:\n",
      "\t [Job finished] jobname: selectfiles.a0 jobid: 0\n",
      "170716-12:11:39,662 workflow INFO:\n",
      "\t [Job finished] jobname: selectfiles.a1 jobid: 1\n",
      "170716-12:11:39,668 workflow INFO:\n",
      "\t Executing: register_template.a0 ID: 2\n",
      "170716-12:11:39,676 workflow INFO:\n",
      "\t [Job finished] jobname: register_template.a0 jobid: 2\n",
      "170716-12:11:39,679 workflow INFO:\n",
      "\t Executing: register_template.a1 ID: 6\n",
      "170716-12:11:39,684 workflow INFO:\n",
      "\t [Job finished] jobname: register_template.a1 jobid: 6\n",
      "170716-12:11:39,687 workflow INFO:\n",
      "\t Executing: xfmFUNC.a0 ID: 3\n",
      "170716-12:11:39,696 workflow INFO:\n",
      "\t [Job finished] jobname: xfmFUNC.a0 jobid: 3\n",
      "170716-12:11:39,698 workflow INFO:\n",
      "\t Executing: xfmCSF.a0 ID: 4\n",
      "170716-12:11:39,705 workflow INFO:\n",
      "\t [Job finished] jobname: xfmCSF.a0 jobid: 4\n",
      "170716-12:11:39,707 workflow INFO:\n",
      "\t Executing: xfmCSF.a1 ID: 7\n",
      "170716-12:11:39,718 workflow INFO:\n",
      "\t [Job finished] jobname: xfmCSF.a1 jobid: 7\n",
      "170716-12:11:39,721 workflow INFO:\n",
      "\t Executing: xfmFUNC.a1 ID: 11\n",
      "170716-12:11:39,731 workflow INFO:\n",
      "\t [Job finished] jobname: xfmFUNC.a1 jobid: 11\n",
      "170716-12:11:39,735 workflow INFO:\n",
      "\t Executing: merge_confs.a0 ID: 5\n",
      "170716-12:11:39,743 workflow INFO:\n",
      "\t Executing: merge_confs.a1 ID: 8\n",
      "170716-12:11:39,746 workflow INFO:\n",
      "\t Executing node merge_confs.a0 in dir: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/merge_confs\n",
      "170716-12:11:39,759 workflow INFO:\n",
      "\t Executing node merge_confs.a1 in dir: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/merge_confs\n",
      "170716-12:11:39,768 workflow DEBUG:\n",
      "\t Needed files: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/xfmCSF/skullstripped_anat_reoriented_resample_seg_0_flirt.nii;/Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/xfmCSF/skullstripped_anat_reoriented_resample_seg_0_flirt.mat;/Users/catcamacho/Box/BABIES/templates/WM_T2wreg_eroded.nii;/Users/catcamacho/Box/BABIES/templates/WM_T2wreg_eroded.mat;/Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/merge_confs/_0x1e3d9fd1418d13af2a62cfe54acccebe_unfinished.json;/Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/merge_confs/_inputs.pklz;/Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/merge_confs/_node.pklz\n",
      "170716-12:11:39,770 workflow DEBUG:\n",
      "\t Needed dirs: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/merge_confs/_report\n",
      "170716-12:11:39,773 workflow DEBUG:\n",
      "\t Removing files: \n",
      "170716-12:11:39,781 workflow DEBUG:\n",
      "\t saved results in /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/merge_confs/result_merge_confs.pklz\n",
      "170716-12:11:39,782 workflow DEBUG:\n",
      "\t Needed files: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/xfmCSF/skullstripped_anat_reoriented_resample_seg_0_flirt.nii;/Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/xfmCSF/skullstripped_anat_reoriented_resample_seg_0_flirt.mat;/Users/catcamacho/Box/BABIES/templates/WM_T2wreg_eroded.nii;/Users/catcamacho/Box/BABIES/templates/WM_T2wreg_eroded.mat;/Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/merge_confs/_0x1e3d9fd1418d13af2a62cfe54acccebe_unfinished.json;/Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/merge_confs/_inputs.pklz;/Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/merge_confs/_node.pklz\n",
      "170716-12:11:39,784 workflow DEBUG:\n",
      "\t Needed dirs: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/merge_confs/_report\n",
      "170716-12:11:39,784 workflow DEBUG:\n",
      "\t writing post-exec report to /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/merge_confs/_report/report.rst\n",
      "170716-12:11:39,786 workflow DEBUG:\n",
      "\t Removing files: \n",
      "170716-12:11:39,788 workflow DEBUG:\n",
      "\t Finished running merge_confs.a0 in dir: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/merge_confs\n",
      "\n",
      "170716-12:11:39,792 workflow INFO:\n",
      "\t [Job finished] jobname: merge_confs.a0 jobid: 5\n",
      "170716-12:11:39,793 workflow DEBUG:\n",
      "\t saved results in /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/merge_confs/result_merge_confs.pklz\n",
      "170716-12:11:39,796 workflow DEBUG:\n",
      "\t writing post-exec report to /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/merge_confs/_report/report.rst\n",
      "170716-12:11:39,798 workflow INFO:\n",
      "\t Executing: compcor.a0 ID: 9\n",
      "170716-12:11:39,799 workflow DEBUG:\n",
      "\t Finished running merge_confs.a1 in dir: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/merge_confs\n",
      "\n",
      "170716-12:11:39,808 workflow INFO:\n",
      "\t [Job finished] jobname: merge_confs.a1 jobid: 8\n",
      "170716-12:11:39,809 workflow INFO:\n",
      "\t Executing node compcor.a0 in dir: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/compcor\n",
      "170716-12:11:39,811 workflow INFO:\n",
      "\t Executing: compcor.a1 ID: 12\n",
      "170716-12:11:39,824 workflow INFO:\n",
      "\t Executing node compcor.a1 in dir: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/compcor\n",
      "170716-12:11:43,787 workflow INFO:\n",
      "\t [Job finished] jobname: compcor.a0 jobid: 9\n",
      "170716-12:11:43,790 workflow INFO:\n",
      "\t Executing: datasink.a0 ID: 10\n",
      "170716-12:11:43,798 workflow INFO:\n",
      "\t Executing node datasink.a0 in dir: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/datasink\n",
      "170716-12:11:43,802 workflow DEBUG:\n",
      "\t Found hashfiles: []\n",
      "170716-12:11:43,810 workflow DEBUG:\n",
      "\t Final hashfile: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/datasink/_0x9ac03aa1e3421f13862b91811d6529fa.json\n",
      "170716-12:11:43,812 workflow DEBUG:\n",
      "\t updatehash=False, overwrite=None, always_run=True, hash_exists=False\n",
      "170716-12:11:43,815 workflow DEBUG:\n",
      "\t Node hash: 9ac03aa1e3421f13862b91811d6529fa\n",
      "170716-12:11:43,818 workflow DEBUG:\n",
      "\t /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/datasink/_0x9ac03aa1e3421f13862b91811d6529fa_unfinished.json found and can_resume is True or Node is a MapNode - resuming execution\n",
      "170716-12:11:43,820 workflow DEBUG:\n",
      "\t Creating /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/datasink\n",
      "170716-12:11:43,822 workflow DEBUG:\n",
      "\t writing pre-exec report to /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/datasink/_report/report.rst\n",
      "170716-12:11:43,831 workflow DEBUG:\n",
      "\t Executing node\n",
      "170716-12:11:43,833 workflow DEBUG:\n",
      "\t copying files to wd [execute=True, linksonly=False]\n",
      "170716-12:11:43,836 interface DEBUG:\n",
      "\t key: components_file files: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/compcor/components_file.txt\n",
      "170716-12:11:43,838 interface DEBUG:\n",
      "\t copyfile: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/compcor/components_file.txt /Users/catcamacho/Box/BABIES/processed/components_file/_subject_id_021-BABIES-T1/components_file.txt\n",
      "170716-12:11:43,843 workflow DEBUG:\n",
      "\t Needed files: /Users/catcamacho/Box/BABIES/processed/components_file/_subject_id_021-BABIES-T1/components_file.txt;/Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/datasink/_0x9ac03aa1e3421f13862b91811d6529fa_unfinished.json;/Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/datasink/_inputs.pklz;/Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/datasink/_node.pklz\n",
      "170716-12:11:43,845 workflow DEBUG:\n",
      "\t Needed dirs: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/datasink/_report\n",
      "170716-12:11:43,847 workflow DEBUG:\n",
      "\t Removing files: \n",
      "170716-12:11:43,853 workflow DEBUG:\n",
      "\t saved results in /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/datasink/result_datasink.pklz\n",
      "170716-12:11:43,855 workflow DEBUG:\n",
      "\t writing post-exec report to /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/datasink/_report/report.rst\n",
      "170716-12:11:43,859 workflow DEBUG:\n",
      "\t Finished running datasink.a0 in dir: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_021-BABIES-T1/datasink\n",
      "\n",
      "170716-12:11:43,868 workflow INFO:\n",
      "\t [Job finished] jobname: compcor.a1 jobid: 12\n",
      "170716-12:11:43,870 workflow INFO:\n",
      "\t [Job finished] jobname: datasink.a0 jobid: 10\n",
      "170716-12:11:43,872 workflow INFO:\n",
      "\t Executing: datasink.a1 ID: 13\n",
      "170716-12:11:43,879 workflow INFO:\n",
      "\t Executing node datasink.a1 in dir: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/datasink\n",
      "170716-12:11:43,882 workflow DEBUG:\n",
      "\t Found hashfiles: []\n",
      "170716-12:11:43,883 workflow DEBUG:\n",
      "\t Final hashfile: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/datasink/_0x1f9b5a4c5884df10d9e5b2813238db34.json\n",
      "170716-12:11:43,885 workflow DEBUG:\n",
      "\t updatehash=False, overwrite=None, always_run=True, hash_exists=False\n",
      "170716-12:11:43,887 workflow DEBUG:\n",
      "\t Node hash: 1f9b5a4c5884df10d9e5b2813238db34\n",
      "170716-12:11:43,888 workflow DEBUG:\n",
      "\t /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/datasink/_0x1f9b5a4c5884df10d9e5b2813238db34_unfinished.json found and can_resume is True or Node is a MapNode - resuming execution\n",
      "170716-12:11:43,890 workflow DEBUG:\n",
      "\t Creating /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/datasink\n",
      "170716-12:11:43,894 workflow DEBUG:\n",
      "\t writing pre-exec report to /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/datasink/_report/report.rst\n",
      "170716-12:11:43,904 workflow DEBUG:\n",
      "\t Executing node\n",
      "170716-12:11:43,906 workflow DEBUG:\n",
      "\t copying files to wd [execute=True, linksonly=False]\n",
      "170716-12:11:43,909 interface DEBUG:\n",
      "\t key: components_file files: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/compcor/components_file.txt\n",
      "170716-12:11:43,911 interface DEBUG:\n",
      "\t copyfile: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/compcor/components_file.txt /Users/catcamacho/Box/BABIES/processed/components_file/_subject_id_033x-BABIES-T1/components_file.txt\n",
      "170716-12:11:43,917 workflow DEBUG:\n",
      "\t Needed files: /Users/catcamacho/Box/BABIES/processed/components_file/_subject_id_033x-BABIES-T1/components_file.txt;/Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/datasink/_0x1f9b5a4c5884df10d9e5b2813238db34_unfinished.json;/Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/datasink/_inputs.pklz;/Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/datasink/_node.pklz\n",
      "170716-12:11:43,919 workflow DEBUG:\n",
      "\t Needed dirs: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/datasink/_report\n",
      "170716-12:11:43,921 workflow DEBUG:\n",
      "\t Removing files: \n",
      "170716-12:11:43,928 workflow DEBUG:\n",
      "\t saved results in /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/datasink/result_datasink.pklz\n",
      "170716-12:11:43,930 workflow DEBUG:\n",
      "\t writing post-exec report to /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/datasink/_report/report.rst\n",
      "170716-12:11:43,934 workflow DEBUG:\n",
      "\t Finished running datasink.a1 in dir: /Users/catcamacho/Box/BABIES/workflows/rs_procwf/_subject_id_033x-BABIES-T1/datasink\n",
      "\n",
      "170716-12:11:43,949 workflow INFO:\n",
      "\t [Job finished] jobname: datasink.a1 jobid: 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x1104ed710>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# workflowname.connect([(node1,node2,[('node1output','node2input')]),\n",
    "#                       (node2,node3,[('node2output','node3input')])\n",
    "#                     ])\n",
    "\n",
    "rs_procwf = Workflow(name='rs_procwf')\n",
    "rs_procwf.connect([(infosource,selectfiles,[('subject_id','subject_id')]),\n",
    "                   (selectfiles,register_template,[('struct','in_file')]),\n",
    "                   (selectfiles,xfmFUNC,[('func','in_file')]),\n",
    "                   (selectfiles,xfmCSF,[('csf','in_file')]),\n",
    "                   (register_template, xfmFUNC,[('out_matrix_file','in_matrix_file')]),\n",
    "                   (register_template, xfmCSF,[('out_matrix_file','in_matrix_file')]),\n",
    "                   (xfmCSF,merge_confs,[('out_file','mask1')]),\n",
    "                   (selectfiles,merge_confs,[('wm','mask2')]),\n",
    "                   (merge_confs,compcor,[('vols','mask_files')]),\n",
    "                   (xfmFUNC,compcor,[('out_file','realigned_file')]),\n",
    "                   (compcor,noise_mat,[('components_file','comp_noise')]),\n",
    "                   (selectfiles,noise_mat,[('vols_to_censor','vols_to_censor')]),\n",
    "                   (selectfiles,noise_mat,[('motion_params','motion_params')]),\n",
    "                   (noise_mat,denoise,[('noise_matrix','design')]),\n",
    "                   (xfmFUNC,denoise,[('out_file','in_file')]),\n",
    "                   (denoise,bandpass,[('out_res','in_file')]),\n",
    "                   (compcor,datasink,[('components_file','components_file')])\n",
    "                   ])\n",
    "\n",
    "rs_procwf.base_dir = workflow_dir\n",
    "rs_procwf.write_graph(graph2use='flat')\n",
    "rs_procwf.run('MultiProc', plugin_args={'n_procs': proc_cores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
